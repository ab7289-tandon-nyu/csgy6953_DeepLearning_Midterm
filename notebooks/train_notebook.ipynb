{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5a2OcE_GwrT",
        "outputId": "4904f2e5-374b-4622-9316-4dc9d615aca1"
      },
      "outputs": [],
      "source": [
        "# !pip install -U \"git+https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # connect to our wandb project\n",
        "# !pip install wandb\n",
        "# !wandb login \"API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ow3lduSvGwrU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alodie/miniconda3/envs/avalanche-dev-env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import sys \n",
        "sys.path.append(\"..\")\n",
        "import time\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJaOta3cmQwI",
        "outputId": "81ddc041-d1ee-410d-ab80-e9a75890b761"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c2CF9rXbGwrU"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JxwCl4lcGwrW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from src.data import get_transformed_data, make_data_loaders\n",
        "from src.transforms import make_transforms\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS  = 200\n",
        "\n",
        "valid_ratio = 0.1\n",
        "\n",
        "train_data, valid_data, test_data = (\n",
        "    get_transformed_data(\n",
        "        make_transforms = make_transforms,\n",
        "        valid_ratio = valid_ratio\n",
        "    )\n",
        ")\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = (\n",
        "    make_data_loaders(\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        test_data,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfPJNbhPGwrW"
      },
      "source": [
        "**Define our Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsPprgn5GwrW",
        "outputId": "3303861d-2a4a-4df6-d556-7874b6d1ccec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alodie/miniconda3/envs/avalanche-dev-env/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "from src.model import ResNet, StemConfig, ResidualBlockType\n",
        "from src.utils import initialize_parameters, epoch_time\n",
        "\n",
        "DROPOUT = 0.1\n",
        "model_architecture = (\n",
        "    (ResidualBlockType.BASIC, 3, 64, DROPOUT),\n",
        "    (ResidualBlockType.BASIC, 5, 128, DROPOUT),\n",
        "    (ResidualBlockType.BOTTLENECK, 26, 256, DROPOUT),\n",
        "    (ResidualBlockType.BOTTLENECK, 5, 512, DROPOUT),\n",
        ")\n",
        "\n",
        "stem_config = StemConfig(num_channels=64, kernel_size=5, stride=1, padding=2)\n",
        "model = ResNet(model_architecture, stem_config=stem_config, output_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "run = \"nish_49m_deep6_cyclic_lr_bottleneck_v2.pt\"\n",
        "path = \"../model/\"\n",
        "file_path = path + run\n",
        "\n",
        "model_file = Path(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-teLbU72GwrX"
      },
      "source": [
        "Need to run a dummy set of data to initialize the lazy modules before we can use torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtRvQ7y_GwrX",
        "outputId": "c338dc30-247a-4b97-94ea-b8baf79c6633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init new model parameters\n",
            "torch.Size([256, 10])\n"
          ]
        }
      ],
      "source": [
        "if model_file.exists() and model_file.is_file():\n",
        "  print(\"Loading model\")\n",
        "  # load our previously trained model\n",
        "  model.load_state_dict(torch.load(model_file))\n",
        "  model = model.to(device)\n",
        "else:\n",
        "  # intialize a new model\n",
        "  print(\"Init new model parameters\")\n",
        "  inputs = torch.empty((BATCH_SIZE, 3, 32, 32))\n",
        "  inputs.normal_()\n",
        "  model = model.to(device)\n",
        "  y = model(inputs.to(device))\n",
        "  print(y.size())\n",
        "\n",
        "  model.apply(initialize_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjqTh-mhGwrX",
        "outputId": "3307be6b-9824-43d1-93f8-cac0d22ab58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 4,997,194 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "from src.utils import count_parameters\n",
        "\n",
        "num_params, grad_params = count_parameters(model)\n",
        "print(f\"There are {grad_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Logging**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnishantaswani\u001b[0m (\u001b[33mdlf22_mini_project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/alodie/git/csgy6953_DeepLearning_Midterm/notebooks/wandb/run-20221121_100426-1v49rta4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/1v49rta4\" target=\"_blank\">nish_49m_deep6_cyclic_lr_bottleneck_v2.pt</a></strong> to <a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/1v49rta4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f89e98f1e20>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# setup wandb logging\n",
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project='Submission_Reproduces_Results',\n",
        "    name=run,\n",
        "    entity=\"dlf22_mini_project\",\n",
        "    config={\n",
        "        \"learning_rate_policy\":\"CyclicLR base=0.0001 ma=x0.5 triangular\",\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"dropout\":DROPOUT,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"architecture\": model_architecture,\n",
        "        \"avg_pool\": 4,\n",
        "        \"num_params\":grad_params,\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training configurations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aN5uGCn-GwrX"
      },
      "outputs": [],
      "source": [
        "from src.engine import train_one_epoch, evaluate\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "best_loss = float('inf')\n",
        "EPOCHS  = 200\n",
        "max_lr = 0.5\n",
        "base_lr = 0.0001\n",
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=learning_rate, cycle_momentum=False)\n",
        "\n",
        "if model_file.is_file():\n",
        "  # if we loaded a previously saved iteration, we want to get the current\n",
        "  # best loss otherwise we could overwrite our save with a worse model\n",
        "  loss, acc = evaluate(model.to(device), test_iterator, criterion, device)\n",
        "  best_loss = loss\n",
        "  print(f\"Prevous best loss: {loss:.4f}, acc: {acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS1DEX_fGwrX",
        "outputId": "8dd0711b-60f5-4a91-db3b-baf76c54de2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\tTrain elapsed: 0:33, loss: 3.4149, acc: 19.00%\n",
            "\tValidation elapsed: 0:1, loss: 2.3849, acc: 23.68%\n",
            "Epoch 2\n",
            "\tTrain elapsed: 0:33, loss: 2.1200, acc: 28.06%\n",
            "\tValidation elapsed: 0:1, loss: 2.1305, acc: 30.54%\n",
            "Epoch 3\n",
            "\tTrain elapsed: 0:33, loss: 1.9064, acc: 33.33%\n",
            "\tValidation elapsed: 0:1, loss: 1.9975, acc: 35.91%\n",
            "Epoch 4\n",
            "\tTrain elapsed: 0:33, loss: 1.7723, acc: 37.49%\n",
            "\tValidation elapsed: 0:1, loss: 1.7380, acc: 42.25%\n",
            "Epoch 5\n",
            "\tTrain elapsed: 0:33, loss: 1.6757, acc: 40.38%\n",
            "\tValidation elapsed: 0:1, loss: 1.6902, acc: 44.77%\n",
            "Epoch 6\n",
            "\tTrain elapsed: 0:33, loss: 1.5960, acc: 42.89%\n",
            "\tValidation elapsed: 0:1, loss: 1.6527, acc: 45.57%\n",
            "Epoch 7\n",
            "\tTrain elapsed: 0:34, loss: 1.5372, acc: 44.75%\n",
            "\tValidation elapsed: 0:1, loss: 1.5254, acc: 48.59%\n",
            "Epoch 8\n",
            "\tTrain elapsed: 0:34, loss: 1.4835, acc: 46.64%\n",
            "\tValidation elapsed: 0:1, loss: 1.4648, acc: 50.87%\n",
            "Epoch 9\n",
            "\tTrain elapsed: 0:34, loss: 1.4298, acc: 48.96%\n",
            "\tValidation elapsed: 0:1, loss: 1.5470, acc: 51.29%\n",
            "Epoch 10\n",
            "\tTrain elapsed: 0:34, loss: 1.3766, acc: 50.60%\n",
            "\tValidation elapsed: 0:1, loss: 1.4172, acc: 52.99%\n",
            "Epoch 11\n",
            "\tTrain elapsed: 0:34, loss: 1.3242, acc: 52.70%\n",
            "\tValidation elapsed: 0:1, loss: 1.2850, acc: 56.45%\n",
            "Epoch 12\n",
            "\tTrain elapsed: 0:34, loss: 1.2679, acc: 54.56%\n",
            "\tValidation elapsed: 0:1, loss: 1.3037, acc: 57.57%\n",
            "Epoch 13\n",
            "\tTrain elapsed: 0:34, loss: 1.2291, acc: 56.63%\n",
            "\tValidation elapsed: 0:1, loss: 1.2630, acc: 58.56%\n",
            "Epoch 14\n",
            "\tTrain elapsed: 0:34, loss: 1.1696, acc: 58.52%\n",
            "\tValidation elapsed: 0:1, loss: 1.1960, acc: 60.59%\n",
            "Epoch 15\n",
            "\tTrain elapsed: 0:34, loss: 1.1201, acc: 60.07%\n",
            "\tValidation elapsed: 0:1, loss: 1.0763, acc: 62.78%\n",
            "Epoch 16\n",
            "\tTrain elapsed: 0:34, loss: 1.0760, acc: 62.06%\n",
            "\tValidation elapsed: 0:1, loss: 1.0955, acc: 63.96%\n",
            "Epoch 17\n",
            "\tTrain elapsed: 0:34, loss: 1.0348, acc: 63.12%\n",
            "\tValidation elapsed: 0:1, loss: 0.9931, acc: 66.15%\n",
            "Epoch 18\n",
            "\tTrain elapsed: 0:34, loss: 1.0001, acc: 64.51%\n",
            "\tValidation elapsed: 0:1, loss: 1.0560, acc: 64.44%\n",
            "Epoch 19\n",
            "\tTrain elapsed: 0:34, loss: 0.9540, acc: 66.30%\n",
            "\tValidation elapsed: 0:1, loss: 1.0045, acc: 66.59%\n",
            "Epoch 20\n",
            "\tTrain elapsed: 0:34, loss: 0.9125, acc: 67.66%\n",
            "\tValidation elapsed: 0:1, loss: 0.9171, acc: 68.17%\n",
            "Epoch 21\n",
            "\tTrain elapsed: 0:34, loss: 0.8959, acc: 68.41%\n",
            "\tValidation elapsed: 0:1, loss: 0.9857, acc: 67.82%\n",
            "Epoch 22\n",
            "\tTrain elapsed: 0:34, loss: 0.8533, acc: 69.74%\n",
            "\tValidation elapsed: 0:1, loss: 0.9158, acc: 70.35%\n",
            "Epoch 23\n",
            "\tTrain elapsed: 0:34, loss: 0.8136, acc: 71.05%\n",
            "\tValidation elapsed: 0:1, loss: 0.8925, acc: 71.05%\n",
            "Epoch 24\n",
            "\tTrain elapsed: 0:34, loss: 0.7818, acc: 72.35%\n",
            "\tValidation elapsed: 0:1, loss: 0.8645, acc: 72.49%\n",
            "Epoch 25\n",
            "\tTrain elapsed: 0:34, loss: 0.7476, acc: 73.50%\n",
            "\tValidation elapsed: 0:1, loss: 0.7744, acc: 74.16%\n",
            "Epoch 26\n",
            "\tTrain elapsed: 0:34, loss: 0.7225, acc: 74.54%\n",
            "\tValidation elapsed: 0:1, loss: 0.7171, acc: 75.68%\n",
            "Epoch 27\n",
            "\tTrain elapsed: 0:34, loss: 0.6899, acc: 75.62%\n",
            "\tValidation elapsed: 0:1, loss: 0.6908, acc: 76.30%\n",
            "Epoch 28\n",
            "\tTrain elapsed: 0:34, loss: 0.6652, acc: 76.45%\n",
            "\tValidation elapsed: 0:1, loss: 0.6821, acc: 77.48%\n",
            "Epoch 29\n",
            "\tTrain elapsed: 0:34, loss: 0.6322, acc: 77.65%\n",
            "\tValidation elapsed: 0:1, loss: 0.6554, acc: 78.55%\n",
            "Epoch 30\n",
            "\tTrain elapsed: 0:34, loss: 0.6160, acc: 78.41%\n",
            "\tValidation elapsed: 0:1, loss: 0.6394, acc: 79.00%\n",
            "Epoch 31\n",
            "\tTrain elapsed: 0:34, loss: 0.5930, acc: 78.99%\n",
            "\tValidation elapsed: 0:1, loss: 0.6886, acc: 76.87%\n",
            "Epoch 32\n",
            "\tTrain elapsed: 0:34, loss: 0.5738, acc: 79.75%\n",
            "\tValidation elapsed: 0:1, loss: 0.6388, acc: 78.87%\n",
            "Epoch 33\n",
            "\tTrain elapsed: 0:34, loss: 0.5537, acc: 80.60%\n",
            "\tValidation elapsed: 0:1, loss: 0.6103, acc: 79.68%\n",
            "Epoch 34\n",
            "\tTrain elapsed: 0:34, loss: 0.5333, acc: 81.27%\n",
            "\tValidation elapsed: 0:1, loss: 0.6140, acc: 80.36%\n",
            "Epoch 35\n",
            "\tTrain elapsed: 0:34, loss: 0.5052, acc: 82.42%\n",
            "\tValidation elapsed: 0:1, loss: 0.5600, acc: 81.54%\n",
            "Epoch 36\n",
            "\tTrain elapsed: 0:34, loss: 0.5013, acc: 82.46%\n",
            "\tValidation elapsed: 0:1, loss: 0.6286, acc: 79.64%\n",
            "Epoch 37\n",
            "\tTrain elapsed: 0:34, loss: 0.4853, acc: 83.07%\n",
            "\tValidation elapsed: 0:1, loss: 0.5569, acc: 81.89%\n",
            "Epoch 38\n",
            "\tTrain elapsed: 0:34, loss: 0.4636, acc: 83.86%\n",
            "\tValidation elapsed: 0:1, loss: 0.5675, acc: 82.11%\n",
            "Epoch 39\n",
            "\tTrain elapsed: 0:34, loss: 0.4500, acc: 84.03%\n",
            "\tValidation elapsed: 0:1, loss: 0.5784, acc: 81.25%\n",
            "Epoch 40\n",
            "\tTrain elapsed: 0:34, loss: 0.4308, acc: 84.79%\n",
            "\tValidation elapsed: 0:1, loss: 0.5522, acc: 82.60%\n",
            "Epoch 41\n",
            "\tTrain elapsed: 0:34, loss: 0.4181, acc: 85.27%\n",
            "\tValidation elapsed: 0:1, loss: 0.5189, acc: 83.80%\n",
            "Epoch 42\n",
            "\tTrain elapsed: 0:34, loss: 0.4032, acc: 85.92%\n",
            "\tValidation elapsed: 0:1, loss: 0.5083, acc: 84.38%\n",
            "Epoch 43\n",
            "\tTrain elapsed: 0:34, loss: 0.3970, acc: 85.86%\n",
            "\tValidation elapsed: 0:1, loss: 0.5318, acc: 83.27%\n",
            "Epoch 44\n",
            "\tTrain elapsed: 0:34, loss: 0.3856, acc: 86.34%\n",
            "\tValidation elapsed: 0:1, loss: 0.4663, acc: 85.16%\n",
            "Epoch 45\n",
            "\tTrain elapsed: 0:34, loss: 0.3658, acc: 87.00%\n",
            "\tValidation elapsed: 0:1, loss: 0.5909, acc: 82.17%\n",
            "Epoch 46\n",
            "\tTrain elapsed: 0:34, loss: 0.3571, acc: 87.47%\n",
            "\tValidation elapsed: 0:1, loss: 0.5067, acc: 83.87%\n",
            "Epoch 47\n",
            "\tTrain elapsed: 0:34, loss: 0.3467, acc: 87.66%\n",
            "\tValidation elapsed: 0:1, loss: 0.4824, acc: 84.88%\n",
            "Epoch 48\n",
            "\tTrain elapsed: 0:34, loss: 0.3362, acc: 88.18%\n",
            "\tValidation elapsed: 0:1, loss: 0.4623, acc: 85.56%\n",
            "Epoch 49\n",
            "\tTrain elapsed: 0:34, loss: 0.3281, acc: 88.30%\n",
            "\tValidation elapsed: 0:1, loss: 0.5061, acc: 84.93%\n",
            "Epoch 50\n",
            "\tTrain elapsed: 0:34, loss: 0.3173, acc: 88.96%\n",
            "\tValidation elapsed: 0:1, loss: 0.4957, acc: 85.55%\n",
            "Epoch 51\n",
            "\tTrain elapsed: 0:34, loss: 0.3081, acc: 89.15%\n",
            "\tValidation elapsed: 0:1, loss: 0.5172, acc: 84.86%\n",
            "Epoch 52\n",
            "\tTrain elapsed: 0:34, loss: 0.2972, acc: 89.56%\n",
            "\tValidation elapsed: 0:1, loss: 0.5445, acc: 84.54%\n",
            "Epoch 53\n",
            "\tTrain elapsed: 0:34, loss: 0.2860, acc: 89.84%\n",
            "\tValidation elapsed: 0:1, loss: 0.4882, acc: 85.30%\n",
            "Epoch 54\n",
            "\tTrain elapsed: 0:34, loss: 0.2768, acc: 90.16%\n",
            "\tValidation elapsed: 0:1, loss: 0.4795, acc: 85.28%\n",
            "Epoch 55\n",
            "\tTrain elapsed: 0:34, loss: 0.2758, acc: 90.26%\n",
            "\tValidation elapsed: 0:1, loss: 0.4679, acc: 85.86%\n",
            "Epoch 56\n",
            "\tTrain elapsed: 0:34, loss: 0.2638, acc: 90.64%\n",
            "\tValidation elapsed: 0:1, loss: 0.4820, acc: 86.37%\n",
            "Epoch 57\n",
            "\tTrain elapsed: 0:34, loss: 0.2675, acc: 90.50%\n",
            "\tValidation elapsed: 0:1, loss: 0.4782, acc: 85.70%\n",
            "Epoch 58\n",
            "\tTrain elapsed: 0:34, loss: 0.2449, acc: 91.29%\n",
            "\tValidation elapsed: 0:1, loss: 0.5016, acc: 86.20%\n",
            "Epoch 59\n",
            "\tTrain elapsed: 0:34, loss: 0.2431, acc: 91.46%\n",
            "\tValidation elapsed: 0:1, loss: 0.4369, acc: 86.71%\n",
            "Epoch 60\n",
            "\tTrain elapsed: 0:34, loss: 0.2359, acc: 91.56%\n",
            "\tValidation elapsed: 0:1, loss: 0.4340, acc: 87.54%\n",
            "Epoch 61\n",
            "\tTrain elapsed: 0:34, loss: 0.2321, acc: 91.80%\n",
            "\tValidation elapsed: 0:1, loss: 0.4373, acc: 87.28%\n",
            "Epoch 62\n",
            "\tTrain elapsed: 0:34, loss: 0.2240, acc: 92.04%\n",
            "\tValidation elapsed: 0:1, loss: 0.4424, acc: 87.31%\n",
            "Epoch 63\n",
            "\tTrain elapsed: 0:34, loss: 0.2198, acc: 92.29%\n",
            "\tValidation elapsed: 0:1, loss: 0.4769, acc: 86.16%\n",
            "Epoch 64\n",
            "\tTrain elapsed: 0:34, loss: 0.2113, acc: 92.36%\n",
            "\tValidation elapsed: 0:1, loss: 0.4913, acc: 86.24%\n",
            "Epoch 65\n",
            "\tTrain elapsed: 0:34, loss: 0.2109, acc: 92.57%\n",
            "\tValidation elapsed: 0:1, loss: 0.4461, acc: 87.24%\n",
            "Epoch 66\n",
            "\tTrain elapsed: 0:34, loss: 0.2052, acc: 92.56%\n",
            "\tValidation elapsed: 0:1, loss: 0.5338, acc: 86.33%\n",
            "Epoch 67\n",
            "\tTrain elapsed: 0:34, loss: 0.1976, acc: 92.96%\n",
            "\tValidation elapsed: 0:1, loss: 0.4728, acc: 87.11%\n",
            "Epoch 68\n",
            "\tTrain elapsed: 0:34, loss: 0.1964, acc: 93.04%\n",
            "\tValidation elapsed: 0:1, loss: 0.5125, acc: 86.32%\n",
            "Epoch 69\n",
            "\tTrain elapsed: 0:34, loss: 0.1892, acc: 93.23%\n",
            "\tValidation elapsed: 0:1, loss: 0.4200, acc: 88.24%\n",
            "Epoch 70\n",
            "\tTrain elapsed: 0:34, loss: 0.1863, acc: 93.40%\n",
            "\tValidation elapsed: 0:1, loss: 0.4922, acc: 86.78%\n",
            "Epoch 71\n",
            "\tTrain elapsed: 0:34, loss: 0.1907, acc: 93.18%\n",
            "\tValidation elapsed: 0:1, loss: 0.5137, acc: 85.71%\n",
            "Epoch 72\n",
            "\tTrain elapsed: 0:34, loss: 0.1778, acc: 93.65%\n",
            "\tValidation elapsed: 0:1, loss: 0.4680, acc: 87.59%\n",
            "Epoch 73\n",
            "\tTrain elapsed: 0:34, loss: 0.1757, acc: 93.70%\n",
            "\tValidation elapsed: 0:1, loss: 0.4857, acc: 87.21%\n",
            "Epoch 74\n",
            "\tTrain elapsed: 0:34, loss: 0.1734, acc: 93.81%\n",
            "\tValidation elapsed: 0:1, loss: 0.5599, acc: 86.04%\n",
            "Epoch 75\n",
            "\tTrain elapsed: 0:34, loss: 0.1614, acc: 94.34%\n",
            "\tValidation elapsed: 0:1, loss: 0.4430, acc: 87.63%\n",
            "Epoch 76\n",
            "\tTrain elapsed: 0:34, loss: 0.1620, acc: 94.19%\n",
            "\tValidation elapsed: 0:1, loss: 0.5000, acc: 86.87%\n",
            "Epoch 77\n",
            "\tTrain elapsed: 0:34, loss: 0.1599, acc: 94.21%\n",
            "\tValidation elapsed: 0:1, loss: 0.4838, acc: 87.32%\n",
            "Epoch 78\n",
            "\tTrain elapsed: 0:34, loss: 0.1560, acc: 94.46%\n",
            "\tValidation elapsed: 0:1, loss: 0.4841, acc: 86.61%\n",
            "Epoch 79\n",
            "\tTrain elapsed: 0:34, loss: 0.1500, acc: 94.59%\n",
            "\tValidation elapsed: 0:1, loss: 0.5273, acc: 87.02%\n",
            "Epoch 80\n",
            "\tTrain elapsed: 0:34, loss: 0.1513, acc: 94.65%\n",
            "\tValidation elapsed: 0:1, loss: 0.4785, acc: 87.30%\n",
            "Epoch 81\n",
            "\tTrain elapsed: 0:34, loss: 0.1535, acc: 94.51%\n",
            "\tValidation elapsed: 0:1, loss: 0.4325, acc: 88.26%\n",
            "Epoch 82\n",
            "\tTrain elapsed: 0:34, loss: 0.1427, acc: 94.90%\n",
            "\tValidation elapsed: 0:1, loss: 0.4967, acc: 87.65%\n",
            "Epoch 83\n",
            "\tTrain elapsed: 0:34, loss: 0.1380, acc: 95.10%\n",
            "\tValidation elapsed: 0:1, loss: 0.4565, acc: 88.38%\n",
            "Epoch 84\n",
            "\tTrain elapsed: 0:34, loss: 0.1417, acc: 94.95%\n",
            "\tValidation elapsed: 0:1, loss: 0.4987, acc: 87.67%\n",
            "Epoch 85\n",
            "\tTrain elapsed: 0:34, loss: 0.1399, acc: 94.96%\n",
            "\tValidation elapsed: 0:1, loss: 0.4530, acc: 87.94%\n",
            "Epoch 86\n",
            "\tTrain elapsed: 0:34, loss: 0.1361, acc: 95.16%\n",
            "\tValidation elapsed: 0:1, loss: 0.5008, acc: 87.98%\n",
            "Epoch 87\n",
            "\tTrain elapsed: 0:34, loss: 0.1385, acc: 95.10%\n",
            "\tValidation elapsed: 0:1, loss: 0.5780, acc: 86.40%\n",
            "Epoch 88\n",
            "\tTrain elapsed: 0:34, loss: 0.1308, acc: 95.27%\n",
            "\tValidation elapsed: 0:1, loss: 0.5068, acc: 87.93%\n",
            "Epoch 89\n",
            "\tTrain elapsed: 0:34, loss: 0.1342, acc: 95.16%\n",
            "\tValidation elapsed: 0:1, loss: 0.4990, acc: 87.89%\n",
            "Epoch 90\n",
            "\tTrain elapsed: 0:34, loss: 0.1261, acc: 95.48%\n",
            "\tValidation elapsed: 0:1, loss: 0.4190, acc: 89.15%\n",
            "Epoch 91\n",
            "\tTrain elapsed: 0:34, loss: 0.1275, acc: 95.48%\n",
            "\tValidation elapsed: 0:1, loss: 0.4396, acc: 88.94%\n",
            "Epoch 92\n",
            "\tTrain elapsed: 0:34, loss: 0.1233, acc: 95.75%\n",
            "\tValidation elapsed: 0:1, loss: 0.4506, acc: 88.53%\n",
            "Epoch 93\n",
            "\tTrain elapsed: 0:34, loss: 0.1223, acc: 95.56%\n",
            "\tValidation elapsed: 0:1, loss: 0.4582, acc: 89.16%\n",
            "Epoch 94\n",
            "\tTrain elapsed: 0:34, loss: 0.1229, acc: 95.71%\n",
            "\tValidation elapsed: 0:1, loss: 0.4470, acc: 89.23%\n",
            "Epoch 95\n",
            "\tTrain elapsed: 0:34, loss: 0.1148, acc: 96.00%\n",
            "\tValidation elapsed: 0:1, loss: 0.4233, acc: 89.11%\n",
            "Epoch 96\n",
            "\tTrain elapsed: 0:34, loss: 0.1128, acc: 95.95%\n",
            "\tValidation elapsed: 0:1, loss: 0.4837, acc: 88.16%\n",
            "Epoch 97\n",
            "\tTrain elapsed: 0:34, loss: 0.1176, acc: 95.89%\n",
            "\tValidation elapsed: 0:1, loss: 0.4118, acc: 89.51%\n",
            "Epoch 98\n",
            "\tTrain elapsed: 0:34, loss: 0.1102, acc: 96.02%\n",
            "\tValidation elapsed: 0:1, loss: 0.4162, acc: 89.75%\n",
            "Epoch 99\n",
            "\tTrain elapsed: 0:34, loss: 0.1121, acc: 96.10%\n",
            "\tValidation elapsed: 0:1, loss: 0.5440, acc: 87.71%\n",
            "Epoch 100\n",
            "\tTrain elapsed: 0:34, loss: 0.1050, acc: 96.36%\n",
            "\tValidation elapsed: 0:1, loss: 0.4783, acc: 88.80%\n",
            "Epoch 101\n",
            "\tTrain elapsed: 0:34, loss: 0.1093, acc: 96.19%\n",
            "\tValidation elapsed: 0:1, loss: 0.5156, acc: 88.14%\n",
            "Epoch 102\n",
            "\tTrain elapsed: 0:34, loss: 0.1091, acc: 96.14%\n",
            "\tValidation elapsed: 0:1, loss: 0.4692, acc: 88.13%\n",
            "Epoch 103\n",
            "\tTrain elapsed: 0:34, loss: 0.1053, acc: 96.26%\n",
            "\tValidation elapsed: 0:1, loss: 0.4435, acc: 89.36%\n",
            "Epoch 104\n",
            "\tTrain elapsed: 0:34, loss: 0.1083, acc: 96.14%\n",
            "\tValidation elapsed: 0:1, loss: 0.4506, acc: 88.86%\n",
            "Epoch 105\n",
            "\tTrain elapsed: 0:34, loss: 0.1020, acc: 96.36%\n",
            "\tValidation elapsed: 0:1, loss: 0.5653, acc: 87.25%\n",
            "Epoch 106\n",
            "\tTrain elapsed: 0:34, loss: 0.0953, acc: 96.57%\n",
            "\tValidation elapsed: 0:1, loss: 0.5202, acc: 87.85%\n",
            "Epoch 107\n",
            "\tTrain elapsed: 0:34, loss: 0.0999, acc: 96.49%\n",
            "\tValidation elapsed: 0:1, loss: 0.4555, acc: 89.13%\n",
            "Epoch 108\n",
            "\tTrain elapsed: 0:34, loss: 0.0993, acc: 96.54%\n",
            "\tValidation elapsed: 0:1, loss: 0.4491, acc: 88.92%\n",
            "Epoch 109\n",
            "\tTrain elapsed: 0:34, loss: 0.1007, acc: 96.45%\n",
            "\tValidation elapsed: 0:1, loss: 0.4521, acc: 89.00%\n",
            "Epoch 110\n",
            "\tTrain elapsed: 0:34, loss: 0.0943, acc: 96.65%\n",
            "\tValidation elapsed: 0:1, loss: 0.4442, acc: 89.27%\n",
            "Epoch 111\n",
            "\tTrain elapsed: 0:34, loss: 0.0942, acc: 96.62%\n",
            "\tValidation elapsed: 0:1, loss: 0.4278, acc: 89.35%\n",
            "Epoch 112\n",
            "\tTrain elapsed: 0:34, loss: 0.0924, acc: 96.78%\n",
            "\tValidation elapsed: 0:1, loss: 0.4555, acc: 89.03%\n",
            "Epoch 113\n",
            "\tTrain elapsed: 0:34, loss: 0.0892, acc: 96.78%\n",
            "\tValidation elapsed: 0:1, loss: 0.4192, acc: 90.28%\n",
            "Epoch 114\n",
            "\tTrain elapsed: 0:34, loss: 0.1092, acc: 96.15%\n",
            "\tValidation elapsed: 0:1, loss: 0.4622, acc: 88.48%\n",
            "Epoch 115\n",
            "\tTrain elapsed: 0:34, loss: 0.0891, acc: 96.83%\n",
            "\tValidation elapsed: 0:1, loss: 0.4482, acc: 89.58%\n",
            "Epoch 116\n",
            "\tTrain elapsed: 0:34, loss: 0.0915, acc: 96.69%\n",
            "\tValidation elapsed: 0:1, loss: 0.4649, acc: 89.52%\n",
            "Epoch 117\n",
            "\tTrain elapsed: 0:34, loss: 0.0886, acc: 96.76%\n",
            "\tValidation elapsed: 0:1, loss: 0.4475, acc: 89.19%\n",
            "Epoch 118\n",
            "\tTrain elapsed: 0:34, loss: 0.0875, acc: 96.86%\n",
            "\tValidation elapsed: 0:1, loss: 0.5978, acc: 88.01%\n",
            "Epoch 119\n",
            "\tTrain elapsed: 0:34, loss: 0.0851, acc: 96.99%\n",
            "\tValidation elapsed: 0:1, loss: 0.4474, acc: 89.68%\n",
            "Epoch 120\n",
            "\tTrain elapsed: 0:34, loss: 0.0965, acc: 96.61%\n",
            "\tValidation elapsed: 0:1, loss: 0.4323, acc: 89.64%\n",
            "Epoch 121\n",
            "\tTrain elapsed: 0:34, loss: 0.0859, acc: 96.96%\n",
            "\tValidation elapsed: 0:1, loss: 0.5724, acc: 88.05%\n",
            "Epoch 122\n",
            "\tTrain elapsed: 0:34, loss: 0.0855, acc: 97.05%\n",
            "\tValidation elapsed: 0:1, loss: 0.4654, acc: 89.67%\n",
            "Epoch 123\n",
            "\tTrain elapsed: 0:34, loss: 0.0812, acc: 97.18%\n",
            "\tValidation elapsed: 0:1, loss: 0.4568, acc: 89.48%\n",
            "Epoch 124\n",
            "\tTrain elapsed: 0:34, loss: 0.0829, acc: 97.12%\n",
            "\tValidation elapsed: 0:1, loss: 0.4713, acc: 88.52%\n",
            "Epoch 125\n",
            "\tTrain elapsed: 0:34, loss: 0.0834, acc: 97.04%\n",
            "\tValidation elapsed: 0:1, loss: 0.4339, acc: 89.81%\n",
            "Epoch 126\n",
            "\tTrain elapsed: 0:34, loss: 0.0829, acc: 97.14%\n",
            "\tValidation elapsed: 0:1, loss: 0.4289, acc: 89.93%\n",
            "Epoch 127\n",
            "\tTrain elapsed: 0:34, loss: 0.0836, acc: 97.13%\n",
            "\tValidation elapsed: 0:1, loss: 0.4487, acc: 89.50%\n",
            "Epoch 128\n",
            "\tTrain elapsed: 0:34, loss: 0.0834, acc: 97.06%\n",
            "\tValidation elapsed: 0:1, loss: 0.4328, acc: 90.32%\n",
            "Epoch 129\n",
            "\tTrain elapsed: 0:34, loss: 0.0760, acc: 97.25%\n",
            "\tValidation elapsed: 0:1, loss: 0.4640, acc: 89.80%\n",
            "Epoch 130\n",
            "\tTrain elapsed: 0:34, loss: 0.0757, acc: 97.35%\n",
            "\tValidation elapsed: 0:1, loss: 0.4468, acc: 90.02%\n",
            "Epoch 131\n",
            "\tTrain elapsed: 0:34, loss: 0.0849, acc: 96.97%\n",
            "\tValidation elapsed: 0:1, loss: 0.4382, acc: 90.03%\n",
            "Epoch 132\n",
            "\tTrain elapsed: 0:34, loss: 0.0720, acc: 97.46%\n",
            "\tValidation elapsed: 0:1, loss: 0.4416, acc: 89.89%\n",
            "Epoch 133\n",
            "\tTrain elapsed: 0:34, loss: 0.0802, acc: 97.14%\n",
            "\tValidation elapsed: 0:1, loss: 0.4714, acc: 89.37%\n",
            "Epoch 134\n",
            "\tTrain elapsed: 0:34, loss: 0.0824, acc: 97.09%\n",
            "\tValidation elapsed: 0:1, loss: 0.4411, acc: 89.36%\n",
            "Epoch 135\n",
            "\tTrain elapsed: 0:34, loss: 0.0748, acc: 97.38%\n",
            "\tValidation elapsed: 0:1, loss: 0.5368, acc: 88.75%\n",
            "Epoch 136\n",
            "\tTrain elapsed: 0:34, loss: 0.0707, acc: 97.52%\n",
            "\tValidation elapsed: 0:1, loss: 0.4728, acc: 90.08%\n",
            "Epoch 137\n",
            "\tTrain elapsed: 0:34, loss: 0.0772, acc: 97.31%\n",
            "\tValidation elapsed: 0:1, loss: 0.4673, acc: 90.20%\n",
            "Epoch 138\n",
            "\tTrain elapsed: 0:34, loss: 0.0691, acc: 97.67%\n",
            "\tValidation elapsed: 0:1, loss: 0.4655, acc: 90.33%\n",
            "Epoch 139\n",
            "\tTrain elapsed: 0:34, loss: 0.0768, acc: 97.33%\n",
            "\tValidation elapsed: 0:1, loss: 0.4694, acc: 90.00%\n",
            "Epoch 140\n",
            "\tTrain elapsed: 0:34, loss: 0.0707, acc: 97.54%\n",
            "\tValidation elapsed: 0:1, loss: 0.4461, acc: 89.66%\n",
            "Epoch 141\n",
            "\tTrain elapsed: 0:34, loss: 0.0717, acc: 97.49%\n",
            "\tValidation elapsed: 0:1, loss: 0.4692, acc: 90.04%\n",
            "Epoch 142\n",
            "\tTrain elapsed: 0:34, loss: 0.0762, acc: 97.38%\n",
            "\tValidation elapsed: 0:1, loss: 0.4134, acc: 90.24%\n",
            "Epoch 143\n",
            "\tTrain elapsed: 0:34, loss: 0.0716, acc: 97.52%\n",
            "\tValidation elapsed: 0:1, loss: 0.4274, acc: 90.40%\n",
            "Epoch 144\n",
            "\tTrain elapsed: 0:34, loss: 0.0681, acc: 97.64%\n",
            "\tValidation elapsed: 0:1, loss: 0.4190, acc: 90.42%\n",
            "Epoch 145\n",
            "\tTrain elapsed: 0:34, loss: 0.0741, acc: 97.41%\n",
            "\tValidation elapsed: 0:1, loss: 0.4110, acc: 90.26%\n",
            "Epoch 146\n",
            "\tTrain elapsed: 0:34, loss: 0.0728, acc: 97.44%\n",
            "\tValidation elapsed: 0:1, loss: 0.4128, acc: 90.06%\n",
            "Epoch 147\n",
            "\tTrain elapsed: 0:34, loss: 0.0644, acc: 97.76%\n",
            "\tValidation elapsed: 0:1, loss: 0.4527, acc: 89.79%\n",
            "Epoch 148\n",
            "\tTrain elapsed: 0:34, loss: 0.0689, acc: 97.63%\n",
            "\tValidation elapsed: 0:1, loss: 0.4827, acc: 89.67%\n",
            "Epoch 149\n",
            "\tTrain elapsed: 0:34, loss: 0.0682, acc: 97.62%\n",
            "\tValidation elapsed: 0:1, loss: 0.4775, acc: 89.54%\n",
            "Epoch 150\n",
            "\tTrain elapsed: 0:34, loss: 0.0604, acc: 97.90%\n",
            "\tValidation elapsed: 0:1, loss: 0.4509, acc: 89.99%\n",
            "Epoch 151\n",
            "\tTrain elapsed: 0:34, loss: 0.0662, acc: 97.74%\n",
            "\tValidation elapsed: 0:1, loss: 0.4520, acc: 89.93%\n",
            "Epoch 152\n",
            "\tTrain elapsed: 0:34, loss: 0.0692, acc: 97.60%\n",
            "\tValidation elapsed: 0:1, loss: 0.4605, acc: 90.06%\n",
            "Epoch 153\n",
            "\tTrain elapsed: 0:34, loss: 0.0634, acc: 97.75%\n",
            "\tValidation elapsed: 0:1, loss: 0.4736, acc: 89.46%\n",
            "Epoch 154\n",
            "\tTrain elapsed: 0:34, loss: 0.0634, acc: 97.76%\n",
            "\tValidation elapsed: 0:1, loss: 0.5159, acc: 89.09%\n",
            "Epoch 155\n",
            "\tTrain elapsed: 0:34, loss: 0.0708, acc: 97.57%\n",
            "\tValidation elapsed: 0:1, loss: 0.4581, acc: 90.11%\n",
            "Epoch 156\n",
            "\tTrain elapsed: 0:34, loss: 0.0632, acc: 97.74%\n",
            "\tValidation elapsed: 0:1, loss: 0.4843, acc: 89.45%\n",
            "Epoch 157\n",
            "\tTrain elapsed: 0:34, loss: 0.0621, acc: 97.83%\n",
            "\tValidation elapsed: 0:1, loss: 0.4627, acc: 90.02%\n",
            "Epoch 158\n",
            "\tTrain elapsed: 0:34, loss: 0.0729, acc: 97.53%\n",
            "\tValidation elapsed: 0:1, loss: 0.4121, acc: 90.75%\n",
            "Epoch 159\n",
            "\tTrain elapsed: 0:34, loss: 0.0630, acc: 97.81%\n",
            "\tValidation elapsed: 0:1, loss: 0.4486, acc: 90.32%\n",
            "Epoch 160\n",
            "\tTrain elapsed: 0:34, loss: 0.0609, acc: 97.93%\n",
            "\tValidation elapsed: 0:1, loss: 0.4280, acc: 90.63%\n",
            "Epoch 161\n",
            "\tTrain elapsed: 0:34, loss: 0.0662, acc: 97.70%\n",
            "\tValidation elapsed: 0:1, loss: 0.4311, acc: 90.32%\n",
            "Epoch 162\n",
            "\tTrain elapsed: 0:34, loss: 0.0658, acc: 97.67%\n",
            "\tValidation elapsed: 0:1, loss: 0.3985, acc: 90.60%\n",
            "Epoch 163\n",
            "\tTrain elapsed: 0:34, loss: 0.0527, acc: 98.18%\n",
            "\tValidation elapsed: 0:1, loss: 0.5149, acc: 88.71%\n",
            "Epoch 164\n",
            "\tTrain elapsed: 0:34, loss: 0.0676, acc: 97.67%\n",
            "\tValidation elapsed: 0:1, loss: 0.4899, acc: 89.09%\n",
            "Epoch 165\n",
            "\tTrain elapsed: 0:34, loss: 0.0615, acc: 97.90%\n",
            "\tValidation elapsed: 0:1, loss: 0.4540, acc: 90.36%\n",
            "Epoch 166\n",
            "\tTrain elapsed: 0:34, loss: 0.0619, acc: 97.86%\n",
            "\tValidation elapsed: 0:1, loss: 0.5103, acc: 89.83%\n",
            "Epoch 167\n",
            "\tTrain elapsed: 0:34, loss: 0.0587, acc: 97.93%\n",
            "\tValidation elapsed: 0:1, loss: 0.4169, acc: 90.92%\n",
            "Epoch 168\n",
            "\tTrain elapsed: 0:34, loss: 0.0604, acc: 97.94%\n",
            "\tValidation elapsed: 0:1, loss: 0.4267, acc: 90.88%\n",
            "Epoch 169\n",
            "\tTrain elapsed: 0:34, loss: 0.0603, acc: 97.95%\n",
            "\tValidation elapsed: 0:1, loss: 0.4546, acc: 89.84%\n",
            "Epoch 170\n",
            "\tTrain elapsed: 0:34, loss: 0.0585, acc: 98.00%\n",
            "\tValidation elapsed: 0:1, loss: 0.4587, acc: 90.33%\n",
            "Epoch 171\n",
            "\tTrain elapsed: 0:34, loss: 0.0572, acc: 98.06%\n",
            "\tValidation elapsed: 0:1, loss: 0.4412, acc: 90.55%\n",
            "Epoch 172\n",
            "\tTrain elapsed: 0:34, loss: 0.0566, acc: 98.07%\n",
            "\tValidation elapsed: 0:1, loss: 0.4149, acc: 90.59%\n",
            "Epoch 173\n",
            "\tTrain elapsed: 0:34, loss: 0.0597, acc: 97.89%\n",
            "\tValidation elapsed: 0:1, loss: 0.4321, acc: 90.37%\n",
            "Epoch 174\n",
            "\tTrain elapsed: 0:34, loss: 0.0604, acc: 97.92%\n",
            "\tValidation elapsed: 0:1, loss: 0.4472, acc: 90.62%\n",
            "Epoch 175\n",
            "\tTrain elapsed: 0:34, loss: 0.0555, acc: 98.11%\n",
            "\tValidation elapsed: 0:1, loss: 0.4438, acc: 90.01%\n",
            "Epoch 176\n",
            "\tTrain elapsed: 0:34, loss: 0.0548, acc: 98.09%\n",
            "\tValidation elapsed: 0:1, loss: 0.4659, acc: 90.75%\n",
            "Epoch 177\n",
            "\tTrain elapsed: 0:34, loss: 0.0576, acc: 98.04%\n",
            "\tValidation elapsed: 0:1, loss: 0.4038, acc: 90.58%\n",
            "Epoch 178\n",
            "\tTrain elapsed: 0:34, loss: 0.0534, acc: 98.13%\n",
            "\tValidation elapsed: 0:1, loss: 0.4309, acc: 90.32%\n",
            "Epoch 179\n",
            "\tTrain elapsed: 0:34, loss: 0.0601, acc: 97.88%\n",
            "\tValidation elapsed: 0:1, loss: 0.4562, acc: 90.10%\n",
            "Epoch 180\n",
            "\tTrain elapsed: 0:34, loss: 0.0601, acc: 97.95%\n",
            "\tValidation elapsed: 0:1, loss: 0.4212, acc: 90.02%\n",
            "Epoch 181\n",
            "\tTrain elapsed: 0:34, loss: 0.0553, acc: 98.08%\n",
            "\tValidation elapsed: 0:1, loss: 0.5279, acc: 89.89%\n",
            "Epoch 182\n",
            "\tTrain elapsed: 0:34, loss: 0.0577, acc: 98.03%\n",
            "\tValidation elapsed: 0:1, loss: 0.4401, acc: 90.67%\n",
            "Epoch 183\n",
            "\tTrain elapsed: 0:34, loss: 0.0509, acc: 98.26%\n",
            "\tValidation elapsed: 0:1, loss: 0.3924, acc: 90.97%\n",
            "Epoch 184\n",
            "\tTrain elapsed: 0:34, loss: 0.0535, acc: 98.16%\n",
            "\tValidation elapsed: 0:1, loss: 0.4530, acc: 90.58%\n",
            "Epoch 185\n",
            "\tTrain elapsed: 0:34, loss: 0.0583, acc: 98.02%\n",
            "\tValidation elapsed: 0:1, loss: 0.4086, acc: 91.35%\n",
            "Epoch 186\n",
            "\tTrain elapsed: 0:34, loss: 0.0528, acc: 98.20%\n",
            "\tValidation elapsed: 0:1, loss: 0.4686, acc: 89.78%\n",
            "Epoch 187\n",
            "\tTrain elapsed: 0:34, loss: 0.0542, acc: 98.18%\n",
            "\tValidation elapsed: 0:1, loss: 0.4619, acc: 90.45%\n",
            "Epoch 188\n",
            "\tTrain elapsed: 0:34, loss: 0.0486, acc: 98.38%\n",
            "\tValidation elapsed: 0:1, loss: 0.4100, acc: 91.09%\n",
            "Epoch 189\n",
            "\tTrain elapsed: 0:34, loss: 0.0574, acc: 98.01%\n",
            "\tValidation elapsed: 0:1, loss: 0.4857, acc: 89.80%\n",
            "Epoch 190\n",
            "\tTrain elapsed: 0:34, loss: 0.0516, acc: 98.23%\n",
            "\tValidation elapsed: 0:1, loss: 0.4373, acc: 90.89%\n",
            "Epoch 191\n",
            "\tTrain elapsed: 0:34, loss: 0.0559, acc: 98.02%\n",
            "\tValidation elapsed: 0:1, loss: 0.4265, acc: 90.92%\n",
            "Epoch 192\n",
            "\tTrain elapsed: 0:34, loss: 0.0533, acc: 98.26%\n",
            "\tValidation elapsed: 0:1, loss: 0.4276, acc: 90.37%\n",
            "Epoch 193\n",
            "\tTrain elapsed: 0:34, loss: 0.0470, acc: 98.31%\n",
            "\tValidation elapsed: 0:1, loss: 0.4236, acc: 91.01%\n",
            "Epoch 194\n",
            "\tTrain elapsed: 0:34, loss: 0.0559, acc: 98.11%\n",
            "\tValidation elapsed: 0:1, loss: 0.5519, acc: 89.15%\n",
            "Epoch 195\n",
            "\tTrain elapsed: 0:34, loss: 0.0514, acc: 98.29%\n",
            "\tValidation elapsed: 0:1, loss: 0.4276, acc: 91.23%\n",
            "Epoch 196\n",
            "\tTrain elapsed: 0:34, loss: 0.0462, acc: 98.43%\n",
            "\tValidation elapsed: 0:1, loss: 0.4670, acc: 90.14%\n",
            "Epoch 197\n",
            "\tTrain elapsed: 0:34, loss: 0.0618, acc: 97.89%\n",
            "\tValidation elapsed: 0:1, loss: 0.4187, acc: 90.93%\n",
            "Epoch 198\n",
            "\tTrain elapsed: 0:34, loss: 0.0494, acc: 98.41%\n",
            "\tValidation elapsed: 0:1, loss: 0.4615, acc: 90.53%\n",
            "Epoch 199\n",
            "\tTrain elapsed: 0:34, loss: 0.0455, acc: 98.44%\n",
            "\tValidation elapsed: 0:1, loss: 0.4605, acc: 90.16%\n",
            "Epoch 200\n",
            "\tTrain elapsed: 0:34, loss: 0.0513, acc: 98.21%\n",
            "\tValidation elapsed: 0:1, loss: 0.4459, acc: 91.07%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    start = time.time()\n",
        "\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    train_loss, train_acc = train_one_epoch(model, train_iterator, criterion, optimizer, device)\n",
        "    train_mins, train_secs = epoch_time(start, time.time())\n",
        "\n",
        "    print(f\"\\tTrain elapsed: {train_mins}:{train_secs}, loss: {train_loss:.4f}, acc: {train_acc * 100:.2f}%\")\n",
        "\n",
        "    start = time.time()\n",
        "    val_loss, val_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    val_mins, val_secs = epoch_time(start, time.time())\n",
        "    scheduler.step()\n",
        "\n",
        "    wandb.log({\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"epoch\": epoch,\n",
        "        \"current_lr\": scheduler.get_last_lr()[0],\n",
        "    })\n",
        "\n",
        "    print(f\"\\tValidation elapsed: {val_mins}:{val_secs}, loss: {val_loss:.4f}, acc: {val_acc * 100:.2f}%\")\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txl2I40ZGwrX"
      },
      "source": [
        "**Evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io_QMFwgGwrX",
        "outputId": "1c3d6a85-24cb-46a9-8cf3-eb839ae6fdba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.3867\n",
            "Test Accuracy: 91.46%\n"
          ]
        }
      ],
      "source": [
        "from src.engine import evaluate\n",
        "model.load_state_dict(torch.load([file_path]))\n",
        "test_loss, test_acc = evaluate(model.to(device), test_iterator, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_acc\": test_acc,\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('avalanche-dev-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "63c2409c66ab1813d30d481af421540c6f5d07c1ba22142d2fad7a26b3f8d585"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
