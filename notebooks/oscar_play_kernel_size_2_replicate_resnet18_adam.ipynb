{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone, Install Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2022.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfovHN-sl04P",
    "outputId": "762ce9e5-7596-46a3-c5bc-3d06c960a90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19(Sat)_09:27:37\n"
     ]
    }
   ],
   "source": [
    "# reference: https://www.programiz.com/python-programming/datetime/current-time\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "print(datetime.now(pytz.timezone('America/New_York')).strftime('%m/%d(%a)_%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEg6gGl4gdFv"
   },
   "source": [
    "# Wandb install, login, import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrgALvYPgMBy",
    "outputId": "2977d30a-3e51-42c0-bc0f-fd4bc9c3a87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.13.5)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: PyYAML in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (65.3.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.11.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: setproctitle in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: pathtools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (4.21.9)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBNArx2fgf-v",
    "outputId": "16cf5853-374d-42f9-99aa-860c7e224aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/studio-lab-user/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login \"6f19b1e6735ebc69af24f18d5b426262416027fb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MP8Tcl1ogjVP"
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFOQTotOdDmI"
   },
   "source": [
    "## Torchsummary Install, Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "293u_6mjdMDE",
    "outputId": "9b018ce3-b4fe-4108-b000-85b5f50e1a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary==1.4.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary==1.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8mq4tcWdOSP",
    "outputId": "b1542b39-5e22-4adf-c000-0765a3d72537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchsummary.torchsummary.summary(model: torch.nn.modules.module.Module, input_data: Union[torch.Tensor, torch.Size, Sequence[torch.Tensor], Sequence[Union[int, Sequence[Any], torch.Size]], NoneType] = None, *args: Any, batch_dim: Optional[int] = 0, branching: bool = True, col_names: Optional[Iterable[str]] = None, col_width: int = 25, depth: int = 3, device: Optional[torch.device] = None, dtypes: Optional[List[torch.dtype]] = None, verbose: int = 1, **kwargs: Any) -> torchsummary.model_statistics.ModelStatistics>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bbnVuzegpXs"
   },
   "source": [
    "## Clone team's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rSPl_TQsiRgl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/csgy6953_DeepLearning_Midterm/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r /content/csgy6953_DeepLearning_Midterm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uw2LzDqIgoQt",
    "outputId": "5edaf1f7-393b-4909-bf3f-6a1f4d2cb6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'csgy6953_DeepLearning_Midterm' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b config_kernel_size_on_updated_main \"https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if running on Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "17_B3oo1glfe"
   },
   "outputs": [],
   "source": [
    "# !cp -r /content/csgy6953_DeepLearning_Midterm/src/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if running on Amazon SageMaker Studio Lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r csgy6953_DeepLearning_Midterm/src/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geVocFZngwER"
   },
   "source": [
    "# Import, Seed, Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Yk6T4FzhgvGv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-QebqUCUgyc-"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lsMOOo-gzTu",
    "outputId": "2057285a-a8a4-4da3-c4af-93cc43552519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br5Rha2PhBoT"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XD28XJ_qg1Ee",
    "outputId": "da4b5e49-0dde-45d9-a701-9d2f538ed793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from src.data import get_transformed_data, make_data_loaders\n",
    "from src.transforms import make_auto_transforms # used to use: make_transforms\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "VALID_RATIO = 0.1\n",
    "\n",
    "train_data, valid_data, test_data = \\\n",
    "get_transformed_data(make_transforms=make_auto_transforms, valid_ratio=VALID_RATIO)\n",
    "\n",
    "train_iter, valid_iter, test_iter = \\\n",
    "make_data_loaders(train_data, valid_data, test_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P0KpocliyKi"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture <<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ORrGNYQGix9m"
   },
   "outputs": [],
   "source": [
    "from src.model import StemConfig, ResidualBlockType, ResNet\n",
    "\n",
    "DROPOUT = 0.1\n",
    "MAIN_BLOCK_KERNEL_SIZE = 2\n",
    "\n",
    "# 1 tuple == 1 layer\n",
    "# block with or without bottleneck, how many blocks in each layer, out_channels, dropout prob, kernel_size\n",
    "architecture = [\n",
    "    (ResidualBlockType.BASIC, 2,  64, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "    (ResidualBlockType.BASIC, 2, 128, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "    (ResidualBlockType.BASIC, 2, 256, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "    (ResidualBlockType.BASIC, 2, 512, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "]\n",
    "\n",
    "# 2022.11/18(5)_p03.59 (Oscar)\n",
    "# slightly reduce the last layer's out_channels to keep overall params under 5M:\n",
    "# 512 -> 5,069,130\n",
    "# 508 -> 5,014,978\n",
    "# 506 -> 5,001,500\n",
    "# 506 -> 4,988,046 <<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bz6S1KmzOjda",
    "outputId": "a88763db-4673-4720-8167-92d9299483a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "config = StemConfig(num_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "model  = ResNet(architecture, stem_config=config, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LwVNRxIUnAJ"
   },
   "source": [
    "## Initialize model shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5Dw4mJFmkKu",
    "outputId": "fcf52fad-438d-45e2-dd04-45d826099fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "-------------------\n",
      "ResNet(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block_2): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (block_3): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_stem): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (block_4): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_stem): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (block_5): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_stem): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "(5069130, 5069130)\n",
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "# intialize a new model\n",
    "\n",
    "inputs = torch.empty((BATCH_SIZE, 3, 32, 32)) #  passed\n",
    "inputs.normal_()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "outputs = model(inputs.to(device)) # internally converts all nn.LazyConv2d layers to nn.Conv2d\n",
    "\n",
    "print('-------------------')\n",
    "print('-------------------')\n",
    "\n",
    "print(model)\n",
    "\n",
    "from src.utils import count_parameters\n",
    "\n",
    "print(count_parameters(model))\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWvfEz42UfD0"
   },
   "source": [
    "## Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJeHP8QWT_mQ",
    "outputId": "bf3b109b-f19e-4a21-bc59-f2f0acfbd077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5069130\n"
     ]
    }
   ],
   "source": [
    "num_parameters, num_parameters_requiring_grad = count_parameters(model)\n",
    "print(num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuhd85NQdSVI",
    "outputId": "0f48182c-0c48-47d4-ec31-8ab3b17b4fa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          1,728\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [-1, 512, 4, 4]           --\n",
       "|    └─Sequential: 2-4                   [-1, 64, 32, 32]          --\n",
       "|    |    └─ResidualBlock: 3-1           [-1, 64, 32, 32]          33,024\n",
       "|    |    └─ResidualBlock: 3-2           [-1, 64, 32, 32]          33,024\n",
       "|    └─Sequential: 2-5                   [-1, 128, 16, 16]         --\n",
       "|    |    └─ResidualBlock: 3-3           [-1, 128, 16, 16]         107,008\n",
       "|    |    └─ResidualBlock: 3-4           [-1, 128, 16, 16]         131,584\n",
       "|    └─Sequential: 2-6                   [-1, 256, 8, 8]           --\n",
       "|    |    └─ResidualBlock: 3-5           [-1, 256, 8, 8]           427,008\n",
       "|    |    └─ResidualBlock: 3-6           [-1, 256, 8, 8]           525,312\n",
       "|    └─Sequential: 2-7                   [-1, 512, 4, 4]           --\n",
       "|    |    └─ResidualBlock: 3-7           [-1, 512, 4, 4]           1,705,984\n",
       "|    |    └─ResidualBlock: 3-8           [-1, 512, 4, 4]           2,099,200\n",
       "├─Sequential: 1-3                        [-1, 10]                  --\n",
       "|    └─AdaptiveAvgPool2d: 2-8            [-1, 512, 1, 1]           --\n",
       "|    └─Flatten: 2-9                      [-1, 512]                 --\n",
       "|    └─Linear: 2-10                      [-1, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 5,069,130\n",
       "Trainable params: 5,069,130\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 292.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 9.47\n",
       "Params size (MB): 19.34\n",
       "Estimated Total Size (MB): 28.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUIET_VERBOSE = 0\n",
    "\n",
    "one_sample_input_shape = (3, 32, 32)\n",
    "\n",
    "summary(model, one_sample_input_shape, verbose = QUIET_VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQKBIE8_UgoP"
   },
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "uXBP9Cm0Up-h"
   },
   "outputs": [],
   "source": [
    "from src.utils import initialize_parameters\n",
    "\n",
    "# initialize model weights\n",
    "model.apply(initialize_parameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xAeC3JkTZPn"
   },
   "source": [
    "# Train, validate, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G8RjsKs0ZjgD"
   },
   "outputs": [],
   "source": [
    "from src.engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "KDl8ESMqTroa"
   },
   "outputs": [],
   "source": [
    "EPOCHS  = 100\n",
    "\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ssSEoTTzTvBI"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "VwTSlzxwTwLf",
    "outputId": "1ea3c3e8-51ae-4a73-b6dc-2c1e22f4cb78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': [(<ResidualBlockType.BASIC: 0>, 2, 64, 0.1, 2),\n",
       "  (<ResidualBlockType.BASIC: 0>, 2, 128, 0.1, 2),\n",
       "  (<ResidualBlockType.BASIC: 0>, 2, 256, 0.1, 2),\n",
       "  (<ResidualBlockType.BASIC: 0>, 2, 512, 0.1, 2)],\n",
       " 'num_params': 5069130,\n",
       " 'main_block_kernel_size': 2,\n",
       " 'dropout': 0.1,\n",
       " 'learning_rate': 0.001,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 100}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setup wandb logging\n",
    "\n",
    "assert 'wandb' in locals() # 'wandb' has been imported already\n",
    "\n",
    "ENTITY_NAME  = 'dlf22_mini_project' # this is our team name\n",
    "\n",
    "# PROJECT_NAME = 'Junk_Test_Project'\n",
    "PROJECT_NAME = 'ResNet_5M'\n",
    "\n",
    "# RUN_NAME     = 'resnet_osca_kernel_size_2_2022.11.18.p04.13'\n",
    "RUN_NAME = 'osca_kernel_size_2_replicate_resnet18_adam'\n",
    "\n",
    "WANDB_CONFIG = \\\n",
    "{\"architecture\"          : architecture,    # the model\n",
    " \"num_params\"            : num_parameters,  # the model\n",
    " \"main_block_kernel_size\": MAIN_BLOCK_KERNEL_SIZE, # the model\n",
    " \"dropout\"       : DROPOUT,         # the model\n",
    " \"learning_rate\" : learning_rate,   # how to gradient descent\n",
    " \"batch_size\"    : BATCH_SIZE,      # how to gradient descent\n",
    " \"epochs\"        : EPOCHS,}         # train for how long\n",
    "\n",
    "WANDB_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mos2000os\u001b[0m (\u001b[33mdlf22_mini_project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/sagemaker-studiolab-notebooks/wandb/run-20221119_143021-3ca381p5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/3ca381p5\" target=\"_blank\">osca_kernel_size_2_replicate_resnet18_adam</a></strong> to <a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/3ca381p5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f216309e6a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb\\\n",
    ".init(name=RUN_NAME, project=PROJECT_NAME, entity=ENTITY_NAME,config=WANDB_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nMyGRL1GUGXH"
   },
   "outputs": [],
   "source": [
    "# save to disk the \"best\" model === the model with the lowest validation loss\n",
    "best_model_path = RUN_NAME + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbWjFOiMULJ3",
    "outputId": "7a24b9cb-06a6-468c-fe23-fac31086cd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\tTrain elapsed: 0:59, loss: 1.7885, acc: 38.11%\n",
      "\tValidation elapsed: 0:1, loss: 1.2392, acc: 55.55%\n",
      "Epoch 2\n",
      "\tTrain elapsed: 0:59, loss: 1.2574, acc: 54.91%\n",
      "\tValidation elapsed: 0:1, loss: 1.1471, acc: 61.46%\n",
      "Epoch 3\n",
      "\tTrain elapsed: 0:58, loss: 1.0527, acc: 62.60%\n",
      "\tValidation elapsed: 0:1, loss: 0.8273, acc: 72.11%\n",
      "Epoch 4\n",
      "\tTrain elapsed: 0:59, loss: 0.8977, acc: 68.31%\n",
      "\tValidation elapsed: 0:1, loss: 0.7882, acc: 72.09%\n",
      "Epoch 5\n",
      "\tTrain elapsed: 0:58, loss: 0.8004, acc: 71.97%\n",
      "\tValidation elapsed: 0:1, loss: 0.6965, acc: 76.19%\n",
      "Epoch 6\n",
      "\tTrain elapsed: 0:57, loss: 0.7103, acc: 75.25%\n",
      "\tValidation elapsed: 0:1, loss: 0.6022, acc: 79.32%\n",
      "Epoch 7\n",
      "\tTrain elapsed: 0:58, loss: 0.6476, acc: 77.51%\n",
      "\tValidation elapsed: 0:1, loss: 0.5951, acc: 79.88%\n",
      "Epoch 8\n",
      "\tTrain elapsed: 0:59, loss: 0.5898, acc: 79.30%\n",
      "\tValidation elapsed: 0:1, loss: 0.5333, acc: 81.70%\n",
      "Epoch 9\n",
      "\tTrain elapsed: 0:57, loss: 0.5466, acc: 80.75%\n",
      "\tValidation elapsed: 0:1, loss: 0.6204, acc: 79.84%\n",
      "Epoch 10\n",
      "\tTrain elapsed: 0:58, loss: 0.5009, acc: 82.64%\n",
      "\tValidation elapsed: 0:1, loss: 0.5289, acc: 82.50%\n",
      "Epoch 11\n",
      "\tTrain elapsed: 0:59, loss: 0.4643, acc: 83.90%\n",
      "\tValidation elapsed: 0:1, loss: 0.5443, acc: 82.64%\n",
      "Epoch 12\n",
      "\tTrain elapsed: 0:59, loss: 0.4230, acc: 85.24%\n",
      "\tValidation elapsed: 0:1, loss: 0.5583, acc: 82.13%\n",
      "Epoch 13\n",
      "\tTrain elapsed: 0:58, loss: 0.4014, acc: 86.21%\n",
      "\tValidation elapsed: 0:1, loss: 0.5565, acc: 82.50%\n",
      "Epoch 14\n",
      "\tTrain elapsed: 0:58, loss: 0.3768, acc: 86.98%\n",
      "\tValidation elapsed: 0:1, loss: 0.5306, acc: 83.36%\n",
      "Epoch 15\n",
      "\tTrain elapsed: 0:59, loss: 0.3533, acc: 87.73%\n",
      "\tValidation elapsed: 0:1, loss: 0.5183, acc: 83.96%\n",
      "Epoch 16\n",
      "\tTrain elapsed: 0:59, loss: 0.3359, acc: 88.50%\n",
      "\tValidation elapsed: 0:1, loss: 0.5674, acc: 82.79%\n",
      "Epoch 17\n",
      "\tTrain elapsed: 0:59, loss: 0.3308, acc: 88.59%\n",
      "\tValidation elapsed: 0:1, loss: 0.5964, acc: 82.56%\n",
      "Epoch 18\n",
      "\tTrain elapsed: 0:59, loss: 0.3106, acc: 89.39%\n",
      "\tValidation elapsed: 0:1, loss: 0.5967, acc: 82.68%\n",
      "Epoch 19\n",
      "\tTrain elapsed: 0:59, loss: 0.3013, acc: 89.68%\n",
      "\tValidation elapsed: 0:1, loss: 0.5689, acc: 84.28%\n",
      "Epoch 20\n",
      "\tTrain elapsed: 1:0, loss: 0.2880, acc: 90.22%\n",
      "\tValidation elapsed: 0:1, loss: 0.5520, acc: 83.46%\n",
      "Epoch 21\n",
      "\tTrain elapsed: 1:0, loss: 0.2780, acc: 90.59%\n",
      "\tValidation elapsed: 0:1, loss: 0.6103, acc: 82.95%\n",
      "Epoch 22\n",
      "\tTrain elapsed: 1:0, loss: 0.2742, acc: 90.54%\n",
      "\tValidation elapsed: 0:1, loss: 0.5468, acc: 84.41%\n",
      "Epoch 23\n",
      "\tTrain elapsed: 1:0, loss: 0.2615, acc: 91.13%\n",
      "\tValidation elapsed: 0:1, loss: 0.5728, acc: 83.46%\n",
      "Epoch 24\n",
      "\tTrain elapsed: 1:0, loss: 0.2629, acc: 91.11%\n",
      "\tValidation elapsed: 0:1, loss: 0.5397, acc: 84.94%\n",
      "Epoch 25\n",
      "\tTrain elapsed: 0:59, loss: 0.2514, acc: 91.42%\n",
      "\tValidation elapsed: 0:1, loss: 0.5734, acc: 84.30%\n",
      "Epoch 26\n",
      "\tTrain elapsed: 0:59, loss: 0.2448, acc: 91.75%\n",
      "\tValidation elapsed: 0:1, loss: 0.5652, acc: 84.47%\n",
      "Epoch 27\n",
      "\tTrain elapsed: 0:59, loss: 0.2360, acc: 91.83%\n",
      "\tValidation elapsed: 0:1, loss: 0.5681, acc: 84.22%\n",
      "Epoch 28\n",
      "\tTrain elapsed: 0:59, loss: 0.2437, acc: 91.62%\n",
      "\tValidation elapsed: 0:1, loss: 0.5453, acc: 84.92%\n",
      "Epoch 29\n",
      "\tTrain elapsed: 0:59, loss: 0.2369, acc: 91.93%\n",
      "\tValidation elapsed: 0:1, loss: 0.5486, acc: 84.69%\n",
      "Epoch 30\n",
      "\tTrain elapsed: 0:59, loss: 0.2276, acc: 92.35%\n",
      "\tValidation elapsed: 0:1, loss: 0.5780, acc: 84.79%\n",
      "Epoch 31\n",
      "\tTrain elapsed: 0:59, loss: 0.2242, acc: 92.48%\n",
      "\tValidation elapsed: 0:1, loss: 0.5457, acc: 84.92%\n",
      "Epoch 32\n",
      "\tTrain elapsed: 0:59, loss: 0.2191, acc: 92.43%\n",
      "\tValidation elapsed: 0:1, loss: 0.5377, acc: 85.27%\n",
      "Epoch 33\n",
      "\tTrain elapsed: 0:59, loss: 0.2198, acc: 92.58%\n",
      "\tValidation elapsed: 0:1, loss: 0.5716, acc: 84.98%\n",
      "Epoch 34\n",
      "\tTrain elapsed: 0:59, loss: 0.2069, acc: 92.96%\n",
      "\tValidation elapsed: 0:1, loss: 0.5442, acc: 85.16%\n",
      "Epoch 35\n",
      "\tTrain elapsed: 0:59, loss: 0.2125, acc: 92.95%\n",
      "\tValidation elapsed: 0:1, loss: 0.5420, acc: 85.76%\n",
      "Epoch 36\n",
      "\tTrain elapsed: 0:59, loss: 0.2059, acc: 93.08%\n",
      "\tValidation elapsed: 0:1, loss: 0.5426, acc: 85.39%\n",
      "Epoch 37\n",
      "\tTrain elapsed: 0:59, loss: 0.2024, acc: 93.15%\n",
      "\tValidation elapsed: 0:1, loss: 0.6015, acc: 84.79%\n",
      "Epoch 38\n",
      "\tTrain elapsed: 0:59, loss: 0.2023, acc: 93.20%\n",
      "\tValidation elapsed: 0:1, loss: 0.5474, acc: 85.70%\n",
      "Epoch 39\n",
      "\tTrain elapsed: 1:0, loss: 0.1992, acc: 93.10%\n",
      "\tValidation elapsed: 0:1, loss: 0.5572, acc: 85.47%\n",
      "Epoch 40\n",
      "\tTrain elapsed: 0:59, loss: 0.1957, acc: 93.33%\n",
      "\tValidation elapsed: 0:1, loss: 0.5911, acc: 84.86%\n",
      "Epoch 41\n",
      "\tTrain elapsed: 0:59, loss: 0.2026, acc: 93.13%\n",
      "\tValidation elapsed: 0:1, loss: 0.5684, acc: 85.53%\n",
      "Epoch 42\n",
      "\tTrain elapsed: 0:59, loss: 0.1894, acc: 93.63%\n",
      "\tValidation elapsed: 0:1, loss: 0.5644, acc: 85.98%\n",
      "Epoch 43\n",
      "\tTrain elapsed: 0:59, loss: 0.1906, acc: 93.50%\n",
      "\tValidation elapsed: 0:1, loss: 0.5943, acc: 85.39%\n",
      "Epoch 44\n",
      "\tTrain elapsed: 0:59, loss: 0.1863, acc: 93.60%\n",
      "\tValidation elapsed: 0:1, loss: 0.5718, acc: 85.68%\n",
      "Epoch 45\n",
      "\tTrain elapsed: 0:59, loss: 0.1865, acc: 93.72%\n",
      "\tValidation elapsed: 0:1, loss: 0.5394, acc: 86.09%\n",
      "Epoch 46\n",
      "\tTrain elapsed: 0:59, loss: 0.1821, acc: 93.67%\n",
      "\tValidation elapsed: 0:1, loss: 0.5436, acc: 85.51%\n",
      "Epoch 47\n",
      "\tTrain elapsed: 0:59, loss: 0.1788, acc: 93.94%\n",
      "\tValidation elapsed: 0:1, loss: 0.5406, acc: 86.35%\n",
      "Epoch 48\n",
      "\tTrain elapsed: 0:59, loss: 0.1750, acc: 94.04%\n",
      "\tValidation elapsed: 0:1, loss: 0.5339, acc: 85.70%\n",
      "Epoch 49\n",
      "\tTrain elapsed: 0:59, loss: 0.1742, acc: 94.07%\n",
      "\tValidation elapsed: 0:1, loss: 0.5179, acc: 86.39%\n",
      "Epoch 50\n",
      "\tTrain elapsed: 1:0, loss: 0.1770, acc: 94.08%\n",
      "\tValidation elapsed: 0:1, loss: 0.5187, acc: 86.33%\n",
      "Epoch 51\n",
      "\tTrain elapsed: 1:0, loss: 0.1785, acc: 94.03%\n",
      "\tValidation elapsed: 0:1, loss: 0.5254, acc: 86.39%\n",
      "Epoch 52\n",
      "\tTrain elapsed: 0:59, loss: 0.1700, acc: 94.25%\n",
      "\tValidation elapsed: 0:1, loss: 0.5224, acc: 86.35%\n",
      "Epoch 53\n",
      "\tTrain elapsed: 1:0, loss: 0.1646, acc: 94.44%\n",
      "\tValidation elapsed: 0:1, loss: 0.5697, acc: 85.10%\n",
      "Epoch 54\n",
      "\tTrain elapsed: 0:59, loss: 0.1713, acc: 94.24%\n",
      "\tValidation elapsed: 0:1, loss: 0.5792, acc: 85.45%\n",
      "Epoch 55\n",
      "\tTrain elapsed: 1:0, loss: 0.1629, acc: 94.50%\n",
      "\tValidation elapsed: 0:1, loss: 0.5624, acc: 86.19%\n",
      "Epoch 56\n",
      "\tTrain elapsed: 1:0, loss: 0.1643, acc: 94.38%\n",
      "\tValidation elapsed: 0:1, loss: 0.5180, acc: 86.97%\n",
      "Epoch 57\n",
      "\tTrain elapsed: 0:57, loss: 0.1731, acc: 94.20%\n",
      "\tValidation elapsed: 0:1, loss: 0.5105, acc: 86.93%\n",
      "Epoch 58\n",
      "\tTrain elapsed: 0:58, loss: 0.1591, acc: 94.55%\n",
      "\tValidation elapsed: 0:1, loss: 0.5459, acc: 86.35%\n",
      "Epoch 59\n",
      "\tTrain elapsed: 0:58, loss: 0.1609, acc: 94.53%\n",
      "\tValidation elapsed: 0:1, loss: 0.5074, acc: 87.44%\n",
      "Epoch 60\n",
      "\tTrain elapsed: 0:58, loss: 0.1554, acc: 94.57%\n",
      "\tValidation elapsed: 0:1, loss: 0.5363, acc: 86.43%\n",
      "Epoch 61\n",
      "\tTrain elapsed: 0:58, loss: 0.1649, acc: 94.42%\n",
      "\tValidation elapsed: 0:1, loss: 0.5225, acc: 86.43%\n",
      "Epoch 62\n",
      "\tTrain elapsed: 0:58, loss: 0.1574, acc: 94.68%\n",
      "\tValidation elapsed: 0:1, loss: 0.5403, acc: 86.74%\n",
      "Epoch 63\n",
      "\tTrain elapsed: 0:58, loss: 0.1533, acc: 94.80%\n",
      "\tValidation elapsed: 0:1, loss: 0.5496, acc: 86.43%\n",
      "Epoch 64\n",
      "\tTrain elapsed: 0:59, loss: 0.1610, acc: 94.52%\n",
      "\tValidation elapsed: 0:1, loss: 0.5463, acc: 86.89%\n",
      "Epoch 65\n",
      "\tTrain elapsed: 0:59, loss: 0.1519, acc: 94.85%\n",
      "\tValidation elapsed: 0:1, loss: 0.5355, acc: 87.03%\n",
      "Epoch 66\n",
      "\tTrain elapsed: 0:59, loss: 0.1534, acc: 94.76%\n",
      "\tValidation elapsed: 0:1, loss: 0.5482, acc: 86.60%\n",
      "Epoch 67\n",
      "\tTrain elapsed: 0:59, loss: 0.1524, acc: 94.85%\n",
      "\tValidation elapsed: 0:1, loss: 0.5559, acc: 86.68%\n",
      "Epoch 68\n",
      "\tTrain elapsed: 0:59, loss: 0.1582, acc: 94.56%\n",
      "\tValidation elapsed: 0:1, loss: 0.5730, acc: 86.50%\n",
      "Epoch 69\n",
      "\tTrain elapsed: 1:0, loss: 0.1515, acc: 94.81%\n",
      "\tValidation elapsed: 0:1, loss: 0.5580, acc: 87.23%\n",
      "Epoch 70\n",
      "\tTrain elapsed: 0:59, loss: 0.1472, acc: 94.98%\n",
      "\tValidation elapsed: 0:1, loss: 0.5298, acc: 87.09%\n",
      "Epoch 71\n",
      "\tTrain elapsed: 0:59, loss: 0.1398, acc: 95.17%\n",
      "\tValidation elapsed: 0:1, loss: 0.5481, acc: 87.01%\n",
      "Epoch 72\n",
      "\tTrain elapsed: 0:59, loss: 0.1502, acc: 94.90%\n",
      "\tValidation elapsed: 0:1, loss: 0.5909, acc: 86.31%\n",
      "Epoch 73\n",
      "\tTrain elapsed: 0:59, loss: 0.1464, acc: 95.03%\n",
      "\tValidation elapsed: 0:1, loss: 0.5174, acc: 87.27%\n",
      "Epoch 74\n",
      "\tTrain elapsed: 0:59, loss: 0.1437, acc: 95.05%\n",
      "\tValidation elapsed: 0:1, loss: 0.5160, acc: 87.07%\n",
      "Epoch 75\n",
      "\tTrain elapsed: 0:59, loss: 0.1417, acc: 95.17%\n",
      "\tValidation elapsed: 0:1, loss: 0.5067, acc: 87.30%\n",
      "Epoch 76\n",
      "\tTrain elapsed: 0:59, loss: 0.1408, acc: 95.20%\n",
      "\tValidation elapsed: 0:1, loss: 0.5615, acc: 86.48%\n",
      "Epoch 77\n",
      "\tTrain elapsed: 0:59, loss: 0.1377, acc: 95.26%\n",
      "\tValidation elapsed: 0:1, loss: 0.5141, acc: 87.91%\n",
      "Epoch 78\n",
      "\tTrain elapsed: 0:59, loss: 0.1433, acc: 95.24%\n",
      "\tValidation elapsed: 0:1, loss: 0.4934, acc: 87.66%\n",
      "Epoch 79\n",
      "\tTrain elapsed: 0:59, loss: 0.1414, acc: 95.18%\n",
      "\tValidation elapsed: 0:1, loss: 0.5020, acc: 87.44%\n",
      "Epoch 80\n",
      "\tTrain elapsed: 1:0, loss: 0.1358, acc: 95.44%\n",
      "\tValidation elapsed: 0:1, loss: 0.5483, acc: 86.84%\n",
      "Epoch 81\n",
      "\tTrain elapsed: 1:0, loss: 0.1356, acc: 95.21%\n",
      "\tValidation elapsed: 0:1, loss: 0.5119, acc: 87.62%\n",
      "Epoch 82\n",
      "\tTrain elapsed: 1:0, loss: 0.1455, acc: 95.05%\n",
      "\tValidation elapsed: 0:1, loss: 0.5213, acc: 87.54%\n",
      "Epoch 83\n",
      "\tTrain elapsed: 1:0, loss: 0.1379, acc: 95.20%\n",
      "\tValidation elapsed: 0:1, loss: 0.5387, acc: 87.25%\n",
      "Epoch 84\n",
      "\tTrain elapsed: 0:59, loss: 0.1352, acc: 95.39%\n",
      "\tValidation elapsed: 0:1, loss: 0.5200, acc: 87.81%\n",
      "Epoch 85\n",
      "\tTrain elapsed: 0:59, loss: 0.1338, acc: 95.37%\n",
      "\tValidation elapsed: 0:1, loss: 0.5432, acc: 87.11%\n",
      "Epoch 86\n",
      "\tTrain elapsed: 0:59, loss: 0.1305, acc: 95.41%\n",
      "\tValidation elapsed: 0:1, loss: 0.5345, acc: 86.99%\n",
      "Epoch 87\n",
      "\tTrain elapsed: 0:59, loss: 0.1358, acc: 95.36%\n",
      "\tValidation elapsed: 0:1, loss: 0.5325, acc: 87.32%\n",
      "Epoch 88\n",
      "\tTrain elapsed: 0:59, loss: 0.1352, acc: 95.41%\n",
      "\tValidation elapsed: 0:1, loss: 0.5365, acc: 87.89%\n",
      "Epoch 89\n",
      "\tTrain elapsed: 0:59, loss: 0.1383, acc: 95.31%\n",
      "\tValidation elapsed: 0:1, loss: 0.5382, acc: 87.38%\n",
      "Epoch 90\n",
      "\tTrain elapsed: 0:59, loss: 0.1329, acc: 95.55%\n",
      "\tValidation elapsed: 0:1, loss: 0.4880, acc: 87.50%\n",
      "Epoch 91\n",
      "\tTrain elapsed: 0:59, loss: 0.1353, acc: 95.42%\n",
      "\tValidation elapsed: 0:1, loss: 0.5107, acc: 87.48%\n",
      "Epoch 92\n",
      "\tTrain elapsed: 0:59, loss: 0.1252, acc: 95.87%\n",
      "\tValidation elapsed: 0:1, loss: 0.5003, acc: 87.68%\n",
      "Epoch 93\n",
      "\tTrain elapsed: 0:59, loss: 0.1279, acc: 95.63%\n",
      "\tValidation elapsed: 0:1, loss: 0.5143, acc: 87.62%\n",
      "Epoch 94\n",
      "\tTrain elapsed: 0:59, loss: 0.1235, acc: 95.84%\n",
      "\tValidation elapsed: 0:1, loss: 0.5505, acc: 87.11%\n",
      "Epoch 95\n",
      "\tTrain elapsed: 0:59, loss: 0.1277, acc: 95.65%\n",
      "\tValidation elapsed: 0:1, loss: 0.5265, acc: 86.86%\n",
      "Epoch 96\n",
      "\tTrain elapsed: 0:58, loss: 0.1250, acc: 95.76%\n",
      "\tValidation elapsed: 0:1, loss: 0.5123, acc: 87.48%\n",
      "Epoch 97\n",
      "\tTrain elapsed: 0:57, loss: 0.1263, acc: 95.67%\n",
      "\tValidation elapsed: 0:1, loss: 0.5028, acc: 87.71%\n",
      "Epoch 98\n",
      "\tTrain elapsed: 0:58, loss: 0.1230, acc: 95.73%\n",
      "\tValidation elapsed: 0:1, loss: 0.4910, acc: 87.66%\n",
      "Epoch 99\n",
      "\tTrain elapsed: 0:58, loss: 0.1242, acc: 95.78%\n",
      "\tValidation elapsed: 0:1, loss: 0.5128, acc: 87.40%\n",
      "Epoch 100\n",
      "\tTrain elapsed: 0:57, loss: 0.1277, acc: 95.66%\n",
      "\tValidation elapsed: 0:1, loss: 0.5105, acc: 88.16%\n"
     ]
    }
   ],
   "source": [
    "from src.utils import epoch_time\n",
    "\n",
    "FIRST_EPOCH = 1\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in range(FIRST_EPOCH, FIRST_EPOCH + EPOCHS):\n",
    "\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    ## TRAIN\n",
    "    start = time.time()\n",
    "    # train\n",
    "    train_loss, train_acc  = train_one_epoch(model, train_iter, criterion, optimizer, device)\n",
    "    # log & echo\n",
    "    train_mins, train_secs = epoch_time(start, time.time())\n",
    "    wandb.log({\"train_loss\": train_loss,\n",
    "               \"train_acc\" : train_acc,\n",
    "               \"epoch\"     : epoch})\n",
    "    print(f\"\\tTrain elapsed: {train_mins}:{train_secs}, loss: {train_loss:.4f}, acc: {train_acc * 100:.2f}%\")\n",
    "\n",
    "    ## VALIDATE\n",
    "    start = time.time()\n",
    "    # validate\n",
    "    val_loss, val_acc  = evaluate(model, valid_iter, criterion, device)\n",
    "    # log & echo   \n",
    "    val_mins, val_secs = epoch_time(start, time.time())\n",
    "    wandb.log({\"val_loss\": val_loss,\n",
    "               \"val_acc\" : val_acc,\n",
    "               \"epoch\"   : epoch,})\n",
    "    print(f\"\\tValidation elapsed: {val_mins}:{val_secs}, loss: {val_loss:.4f}, acc: {val_acc * 100:.2f}%\")\n",
    "\n",
    "    ## Memorize \"best\" model === the model with the lowest validation loss\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5373\n",
      "Test Accuracy: 87.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: - 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model.to(device), test_iter, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_acc\": test_acc,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPB3dA48fr5UdGHdZAuxlJL",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
