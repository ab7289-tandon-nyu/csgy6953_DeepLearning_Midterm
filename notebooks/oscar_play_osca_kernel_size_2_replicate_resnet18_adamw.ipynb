{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone, Install Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2022.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfovHN-sl04P",
    "outputId": "762ce9e5-7596-46a3-c5bc-3d06c960a90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19(Sat)_09:32:54\n"
     ]
    }
   ],
   "source": [
    "# reference: https://www.programiz.com/python-programming/datetime/current-time\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "print(datetime.now(pytz.timezone('America/New_York')).strftime('%m/%d(%a)_%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEg6gGl4gdFv"
   },
   "source": [
    "# Wandb install, login, import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrgALvYPgMBy",
    "outputId": "2977d30a-3e51-42c0-bc0f-fd4bc9c3a87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.13.5)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (65.3.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.11.0)\n",
      "Requirement already satisfied: pathtools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (4.21.9)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: setproctitle in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBNArx2fgf-v",
    "outputId": "16cf5853-374d-42f9-99aa-860c7e224aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/studio-lab-user/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login \"6f19b1e6735ebc69af24f18d5b426262416027fb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MP8Tcl1ogjVP"
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFOQTotOdDmI"
   },
   "source": [
    "## Torchsummary Install, Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "293u_6mjdMDE",
    "outputId": "9b018ce3-b4fe-4108-b000-85b5f50e1a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary==1.4.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary==1.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8mq4tcWdOSP",
    "outputId": "b1542b39-5e22-4adf-c000-0765a3d72537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchsummary.torchsummary.summary(model: torch.nn.modules.module.Module, input_data: Union[torch.Tensor, torch.Size, Sequence[torch.Tensor], Sequence[Union[int, Sequence[Any], torch.Size]], NoneType] = None, *args: Any, batch_dim: Optional[int] = 0, branching: bool = True, col_names: Optional[Iterable[str]] = None, col_width: int = 25, depth: int = 3, device: Optional[torch.device] = None, dtypes: Optional[List[torch.dtype]] = None, verbose: int = 1, **kwargs: Any) -> torchsummary.model_statistics.ModelStatistics>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bbnVuzegpXs"
   },
   "source": [
    "## Clone team's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rSPl_TQsiRgl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/csgy6953_DeepLearning_Midterm/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r /content/csgy6953_DeepLearning_Midterm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uw2LzDqIgoQt",
    "outputId": "5edaf1f7-393b-4909-bf3f-6a1f4d2cb6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'csgy6953_DeepLearning_Midterm' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b config_kernel_size_on_updated_main \"https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if running on Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "17_B3oo1glfe"
   },
   "outputs": [],
   "source": [
    "# !cp -r /content/csgy6953_DeepLearning_Midterm/src/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if running on Amazon SageMaker Studio Lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r csgy6953_DeepLearning_Midterm/src/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geVocFZngwER"
   },
   "source": [
    "# Import, Seed, Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Yk6T4FzhgvGv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-QebqUCUgyc-"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lsMOOo-gzTu",
    "outputId": "2057285a-a8a4-4da3-c4af-93cc43552519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br5Rha2PhBoT"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XD28XJ_qg1Ee",
    "outputId": "da4b5e49-0dde-45d9-a701-9d2f538ed793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from src.data import get_transformed_data, make_data_loaders\n",
    "from src.transforms import make_auto_transforms # used to use: make_transforms\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "VALID_RATIO = 0.1\n",
    "\n",
    "train_data, valid_data, test_data = \\\n",
    "get_transformed_data(make_transforms=make_auto_transforms, valid_ratio=VALID_RATIO)\n",
    "\n",
    "train_iter, valid_iter, test_iter = \\\n",
    "make_data_loaders(train_data, valid_data, test_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P0KpocliyKi"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture <<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ORrGNYQGix9m"
   },
   "outputs": [],
   "source": [
    "from src.model import StemConfig, ResidualBlockType, ResNet\n",
    "\n",
    "DROPOUT = 0.1\n",
    "MAIN_BLOCK_KERNEL_SIZE = 2\n",
    "\n",
    "# 1 tuple == 1 layer\n",
    "# block with or without bottleneck, how many blocks in each layer, out_channels, dropout prob, kernel_size\n",
    "architecture = [\n",
    "    (ResidualBlockType.BASIC, 2,  64, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "    (ResidualBlockType.BASIC, 2, 128, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "    (ResidualBlockType.BASIC, 2, 256, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "    (ResidualBlockType.BASIC, 2, 512, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
    "]\n",
    "\n",
    "# 2022.11/18(5)_p03.59 (Oscar)\n",
    "# slightly reduce the last layer's out_channels to keep overall params under 5M:\n",
    "# 512 -> 5,069,130\n",
    "# 508 -> 5,014,978\n",
    "# 507 -> 5,001,500\n",
    "# 506 -> 4,988,046 <<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bz6S1KmzOjda",
    "outputId": "a88763db-4673-4720-8167-92d9299483a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "config = StemConfig(num_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "model  = ResNet(architecture, stem_config=config, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LwVNRxIUnAJ"
   },
   "source": [
    "## Initialize model shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5Dw4mJFmkKu",
    "outputId": "fcf52fad-438d-45e2-dd04-45d826099fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "-------------------\n",
      "ResNet(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block_2): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (block_3): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_stem): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (block_4): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_stem): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "    (block_5): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_stem): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (out): ReLU(inplace=True)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (identity): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "(5069130, 5069130)\n",
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "# intialize a new model\n",
    "\n",
    "inputs = torch.empty((BATCH_SIZE, 3, 32, 32)) #  passed\n",
    "inputs.normal_()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "outputs = model(inputs.to(device)) # internally converts all nn.LazyConv2d layers to nn.Conv2d\n",
    "\n",
    "print('-------------------')\n",
    "print('-------------------')\n",
    "\n",
    "print(model)\n",
    "\n",
    "from src.utils import count_parameters\n",
    "\n",
    "print(count_parameters(model))\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWvfEz42UfD0"
   },
   "source": [
    "## Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJeHP8QWT_mQ",
    "outputId": "bf3b109b-f19e-4a21-bc59-f2f0acfbd077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5069130\n"
     ]
    }
   ],
   "source": [
    "num_parameters, num_parameters_requiring_grad = count_parameters(model)\n",
    "print(num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuhd85NQdSVI",
    "outputId": "0f48182c-0c48-47d4-ec31-8ab3b17b4fa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          1,728\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [-1, 512, 4, 4]           --\n",
       "|    └─Sequential: 2-4                   [-1, 64, 32, 32]          --\n",
       "|    |    └─ResidualBlock: 3-1           [-1, 64, 32, 32]          33,024\n",
       "|    |    └─ResidualBlock: 3-2           [-1, 64, 32, 32]          33,024\n",
       "|    └─Sequential: 2-5                   [-1, 128, 16, 16]         --\n",
       "|    |    └─ResidualBlock: 3-3           [-1, 128, 16, 16]         107,008\n",
       "|    |    └─ResidualBlock: 3-4           [-1, 128, 16, 16]         131,584\n",
       "|    └─Sequential: 2-6                   [-1, 256, 8, 8]           --\n",
       "|    |    └─ResidualBlock: 3-5           [-1, 256, 8, 8]           427,008\n",
       "|    |    └─ResidualBlock: 3-6           [-1, 256, 8, 8]           525,312\n",
       "|    └─Sequential: 2-7                   [-1, 512, 4, 4]           --\n",
       "|    |    └─ResidualBlock: 3-7           [-1, 512, 4, 4]           1,705,984\n",
       "|    |    └─ResidualBlock: 3-8           [-1, 512, 4, 4]           2,099,200\n",
       "├─Sequential: 1-3                        [-1, 10]                  --\n",
       "|    └─AdaptiveAvgPool2d: 2-8            [-1, 512, 1, 1]           --\n",
       "|    └─Flatten: 2-9                      [-1, 512]                 --\n",
       "|    └─Linear: 2-10                      [-1, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 5,069,130\n",
       "Trainable params: 5,069,130\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 292.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 9.47\n",
       "Params size (MB): 19.34\n",
       "Estimated Total Size (MB): 28.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUIET_VERBOSE = 0\n",
    "\n",
    "one_sample_input_shape = (3, 32, 32)\n",
    "\n",
    "summary(model, one_sample_input_shape, verbose = QUIET_VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQKBIE8_UgoP"
   },
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uXBP9Cm0Up-h"
   },
   "outputs": [],
   "source": [
    "from src.utils import initialize_parameters\n",
    "\n",
    "# initialize model weights\n",
    "model.apply(initialize_parameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xAeC3JkTZPn"
   },
   "source": [
    "# Train, validate, log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer, scheduler (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_lr        = 0.5\n",
    "base_lr       = 0.0001\n",
    "\n",
    "lr_schedule   = 'CyclicLR_base_0.0001_max_0.5'\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=learning_rate, cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G8RjsKs0ZjgD"
   },
   "outputs": [],
   "source": [
    "from src.engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS  = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "VwTSlzxwTwLf",
    "outputId": "1ea3c3e8-51ae-4a73-b6dc-2c1e22f4cb78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': [(<ResidualBlockType.BASIC: 0>, 2, 64, 0.1, 2),\n",
       "  (<ResidualBlockType.BASIC: 0>, 2, 128, 0.1, 2),\n",
       "  (<ResidualBlockType.BASIC: 0>, 2, 256, 0.1, 2),\n",
       "  (<ResidualBlockType.BASIC: 0>, 2, 512, 0.1, 2)],\n",
       " 'num_params': 5069130,\n",
       " 'main_block_kernel_size': 2,\n",
       " 'dropout': 0.1,\n",
       " 'learning_rate': 0.01,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setup wandb logging\n",
    "\n",
    "assert 'wandb' in locals() # 'wandb' has been imported already\n",
    "\n",
    "ENTITY_NAME  = 'dlf22_mini_project' # this is our team name\n",
    "\n",
    "# PROJECT_NAME = 'Junk_Test_Project'\n",
    "PROJECT_NAME = 'ResNet_5M'\n",
    "\n",
    "# RUN_NAME     = 'resnet_osca_kernel_size_2_2022.11.18.p04.13'\n",
    "RUN_NAME = 'osca_kernel_size_2_replicate_resnet18_adamw'\n",
    "\n",
    "WANDB_CONFIG = \\\n",
    "{\"architecture\"          : architecture,                 # the model\n",
    " \"num_params\"            : num_parameters,                # the model\n",
    " \"grad_params\"           : num_parameters_requiring_grad, # the model\n",
    " \"main_block_kernel_size\": MAIN_BLOCK_KERNEL_SIZE,        # the model\n",
    " \"dropout\"       : DROPOUT,         # the model\n",
    " \"learning_rate\" : learning_rate,   # how to gradient descent\n",
    " \"lr_schedule\"   : lr_schedule,     # how to gradient descent\n",
    " \"batch_size\"    : BATCH_SIZE,      # how to gradient descent\n",
    " \"epochs\"        : EPOCHS,}         # train for how long\n",
    "\n",
    "WANDB_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:36sd927z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69397ab6bdff44ada4023f7d9f303a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">osca_kernel_size_2_replicate_resnet18_adamw</strong>: <a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/36sd927z\" target=\"_blank\">https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/36sd927z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221119_143635-36sd927z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:36sd927z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47395a619df1433e873a3f0b3e5b07ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668257250012176, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/sagemaker-studiolab-notebooks/wandb/run-20221119_143756-1nxktffy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/1nxktffy\" target=\"_blank\">osca_kernel_size_2_replicate_resnet18_adamw</a></strong> to <a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/1nxktffy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f240810ee20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb\\\n",
    ".init(name=RUN_NAME, project=PROJECT_NAME, entity=ENTITY_NAME,config=WANDB_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nMyGRL1GUGXH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osca_kernel_size_2_replicate_resnet18_adamw.pt\n"
     ]
    }
   ],
   "source": [
    "# save to disk the \"best\" model === the model with the lowest validation loss\n",
    "best_model_path = RUN_NAME + '.pt'\n",
    "print(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbWjFOiMULJ3",
    "outputId": "7a24b9cb-06a6-468c-fe23-fac31086cd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\tTrain elapsed: 1:5, loss: 2.0357, acc: 27.80%\n",
      "\tValidation elapsed: 0:1, loss: 1.6630, acc: 39.04%\n",
      "0.00010495000000000166\n",
      "Epoch 2\n",
      "\tTrain elapsed: 1:2, loss: 1.6995, acc: 38.63%\n",
      "\tValidation elapsed: 0:1, loss: 1.4054, acc: 49.10%\n",
      "0.00010989999999999892\n",
      "Epoch 3\n",
      "\tTrain elapsed: 1:4, loss: 1.5574, acc: 43.62%\n",
      "\tValidation elapsed: 0:1, loss: 1.2502, acc: 54.84%\n",
      "0.00011485000000000057\n"
     ]
    }
   ],
   "source": [
    "from src.utils import epoch_time\n",
    "\n",
    "FIRST_EPOCH = 1\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in range(FIRST_EPOCH, FIRST_EPOCH + EPOCHS):\n",
    "\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    ## TRAIN\n",
    "    start = time.time()\n",
    "    # train\n",
    "    train_loss, train_acc  = train_one_epoch(model, train_iter, criterion, optimizer, device)\n",
    "    # log & echo\n",
    "    train_mins, train_secs = epoch_time(start, time.time())\n",
    "    wandb.log({\"train_loss\": train_loss,\n",
    "               \"train_acc\" : train_acc,\n",
    "               \"epoch\"     : epoch})\n",
    "    print(f\"\\tTrain elapsed: {train_mins}:{train_secs}, loss: {train_loss:.4f}, acc: {train_acc * 100:.2f}%\")\n",
    "\n",
    "    ## VALIDATE\n",
    "    start = time.time()\n",
    "    # validate\n",
    "    val_loss, val_acc  = evaluate(model, valid_iter, criterion, device)\n",
    "    # log & echo   \n",
    "    val_mins, val_secs = epoch_time(start, time.time())\n",
    "    wandb.log({\"val_loss\": val_loss,\n",
    "               \"val_acc\" : val_acc,\n",
    "               \"epoch\"   : epoch,})\n",
    "    print(f\"\\tValidation elapsed: {val_mins}:{val_secs}, loss: {val_loss:.4f}, acc: {val_acc * 100:.2f}%\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    wandb.log({\"current_lr\": current_lr,\n",
    "               \"current_learning_rate\": current_lr,\n",
    "               \"epoch\"     : epoch})\n",
    "    \n",
    "    ## Memorize \"best\" model === the model with the lowest validation loss\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osca_kernel_size_2_replicate_resnet18_adamw.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_model_path),\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2691\n",
      "Test Accuracy: 53.74%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model.to(device), test_iter, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_acc\" : test_acc,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPB3dA48fr5UdGHdZAuxlJL",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e8299d72dfe468fd613ffad4039e402b7a97d3c9e4e820f9c8d9bd7574a5870"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
