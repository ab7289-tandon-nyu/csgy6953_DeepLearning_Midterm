{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO0coHfzpcIuiZ+6/VRcZ6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm/blob/oscar1/notebooks/try_residual_bottleneck_block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Our Team's Code"
      ],
      "metadata": {
        "id": "F-Gkq8hQtGZr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hL05a-mszwo",
        "outputId": "af37af80-e4e0-4993-a090-2f865cb60390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'csgy6953_DeepLearning_Midterm' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b bottleneck \"https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/csgy6953_DeepLearning_Midterm/src/ ."
      ],
      "metadata": {
        "id": "vjoAlDLBtQ06"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see whether the latest commit was cloned here:"
      ],
      "metadata": {
        "id": "L84qRL6stcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVIWd5EGtY7x",
        "outputId": "8c19c798-7d7b-47f0-ea82-570d5925e81f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import torch\n",
            "import torch.nn as nn\n",
            "from enum import Enum \n",
            "\n",
            "from typing import List, Tuple, Optional\n",
            "\n",
            "class ResidualBlockType(Enum):\n",
            "    '''\n",
            "    Enum class to represent the residual block type for ResNet\n",
            "    '''\n",
            "    BASIC = 0\n",
            "    BOTTLENECK = 1\n",
            "    \n",
            "class ResidualBlock(nn.Module):\n",
            "    '''\n",
            "    Class representing a convolutional residual block \n",
            "    '''\n",
            "\n",
            "    def __init__(self, num_channels: int, use_stem: bool = False, strides: int = 1):\n",
            "        '''\n",
            "        Creates a new instance of a Residual Block\n",
            "        @param: num_channels (int) - the number of output channels for all convolutions in \n",
            "            the block\n",
            "        @param: use_stem (bool) - whether a 1x1 convolution is needed to downsample the\n",
            "            residual\n",
            "        @param: strides (int) - the number of strides to use in the convolutions, defaults to 1\n",
            "        '''\n",
            "        super().__init__()\n",
            "        self.num_channels = num_channels\n",
            "        self.use_stem = use_stem\n",
            "        self.strides = strides\n",
            "\n",
            "        self.conv1 = nn.LazyConv2d(\n",
            "            num_channels, kernel_size=3, padding=1, stride=strides)\n",
            "        self.conv2 = nn.LazyConv2d(\n",
            "            num_channels, kernel_size=3, padding=1)\n",
            "        self.relu = nn.ReLU(inplace=True)\n",
            "        self.out = nn.ReLU(inplace=True)\n",
            "        self.bn1 = nn.LazyBatchNorm2d()\n",
            "        self.bn2 = nn.LazyBatchNorm2d()\n",
            "\n",
            "        self.conv_stem = None\n",
            "        if use_stem:\n",
            "            self.conv_stem = nn.LazyConv2d(\n",
            "                num_channels, kernel_size=1, stride=strides)\n",
            "\n",
            "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
            "        shortcut = inputs\n",
            "        x = self.relu(self.bn1(self.conv1(inputs)))\n",
            "        x = self.bn2(self.conv2(x))\n",
            "        if self.use_stem:\n",
            "            # downsample skip connection\n",
            "            shortcut = self.conv_stem(shortcut)\n",
            "\n",
            "        # add in skip connection\n",
            "        x += shortcut\n",
            "        return self.out(x)\n",
            "\n",
            "\n",
            "class ResidualBottleNeck(nn.Module):\n",
            "    '''\n",
            "    Class representing a convolutional residual block with a bottleneck\n",
            "    This class was built with reference to: \n",
            "    https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
            "    '''\n",
            "\n",
            "    def __init__(self, num_channels: int, use_stem: bool = False, strides: int=1, factor: int=4):\n",
            "        '''\n",
            "        Creates a new instance of a Residual BottleNeck Block\n",
            "        @param: num_channels (int) - the number of output channels for all convolutions in the block\n",
            "        @param: use_stem (bool) - whether a 1x1 convolution is needed to downsample the residual\n",
            "        @param: strides (int) - the number of strides to use in the convolutions, defaults to 1\n",
            "        @param: factor (int) - the factor by which the input channels will be reduced for the bottleneck\n",
            "        '''\n",
            "        super().__init__()\n",
            "        self.num_channels = num_channels\n",
            "        self.use_stem = use_stem\n",
            "        self.strides = strides\n",
            "        self.factor = factor\n",
            "\n",
            "        # First convolutional layer with normalization\n",
            "        self.conv1 = nn.LazyConv2d(\n",
            "            num_channels//factor, kernel_size=1, padding=0)\n",
            "        self.bn1 = nn.LazyBatchNorm2d()\n",
            "        \n",
            "        # Second convolutional layer with normalization\n",
            "        self.conv2 = nn.LazyConv2d(\n",
            "            num_channels//factor, kernel_size=3, padding=1, stride=strides)\n",
            "        self.bn2 = nn.LazyBatchNorm2d()\n",
            "        \n",
            "        # Third convolutional layer with normalization\n",
            "        self.conv3 = nn.LazyConv2d(\n",
            "            num_channels, kernel_size=1, padding=0)\n",
            "        self.bn3 = nn.LazyBatchNorm2d()\n",
            "\n",
            "        self.relu = nn.ReLU(inplace=True)\n",
            "\n",
            "        self.conv_stem = None\n",
            "        if use_stem:\n",
            "            # Bottleneck residual block \n",
            "            self.conv_stem = nn.LazyConv2d(\n",
            "                num_channels, kernel_size=1, stride=strides)\n",
            "\n",
            "\n",
            "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
            "        shortcut = inputs\n",
            "        x = self.relu(self.bn1(self.conv1(inputs)))\n",
            "        x = self.relu(self.bn2(self.conv2(x)))\n",
            "        x = self.bn3(self.conv3(x))\n",
            "        if self.use_stem:\n",
            "            # downsample skip connection\n",
            "            shortcut = self.conv_stem(shortcut)\n",
            "\n",
            "        # add in skip connection\n",
            "        x += shortcut\n",
            "        return self.relu(x)\n",
            "\n",
            "class StemConfig:\n",
            "    '''\n",
            "    convenience class to encapsulate configuration options\n",
            "    for the ResNet stem\n",
            "    '''\n",
            "    def __init__(self, num_channels, kernel_size, stride, padding):\n",
            "        self.num_channels = num_channels\n",
            "        self.kernel_size = kernel_size\n",
            "        self.stride = stride\n",
            "        self.padding = padding\n",
            "\n",
            "\n",
            "\n",
            "class ResNet(nn.Module):\n",
            "    '''\n",
            "    Class representing a full ResNet model\n",
            "    '''\n",
            "\n",
            "    def __init__(self, architecture: List[Tuple[ResidualBlockType,int,int]], stem_config: Optional[StemConfig], output_size: int = 10, *args, **kwargs):\n",
            "        '''\n",
            "        returns an instance of a ResNet\n",
            "        '''\n",
            "        super().__init__()\n",
            "        if stem_config is not None:\n",
            "            self.stem = self.create_stem(\n",
            "                stem_config.num_channels,\n",
            "                stem_config.kernel_size,\n",
            "                stem_config.stride,\n",
            "                stem_config.padding\n",
            "            )\n",
            "        else:\n",
            "            self.stem = self.create_stem()\n",
            "        self.classifier = self.create_classifier(output_size)\n",
            "\n",
            "        self.body = nn.Sequential()\n",
            "        for idx, layer_def in enumerate(architecture):\n",
            "            self.body.add_module(f\"block_{idx+2}\", self.create_block(*layer_def, first_block=(idx == 0)))\n",
            "\n",
            "\n",
            "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
            "        \"\"\"\n",
            "        Performs forward pass of the inputs through the network\n",
            "        \"\"\"\n",
            "        x = self.stem(inputs)\n",
            "        x = self.body(x)\n",
            "        return self.classifier(x)\n",
            "\n",
            "\n",
            "    def create_stem(self, num_channels: int = 64, kernel_size: int = 7, stride: int = 2, padding: int = 3) \\\n",
            "            -> nn.Sequential:\n",
            "        \"\"\"\n",
            "        Creates a sequential stem as the first component of the model\n",
            "        \"\"\"\n",
            "        return nn.Sequential(\n",
            "            nn.LazyConv2d(num_channels, kernel_size=kernel_size,\n",
            "                          padding=padding, stride=stride),\n",
            "            nn.LazyBatchNorm2d(),\n",
            "            nn.ReLU(inplace=True),\n",
            "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
            "        )\n",
            "\n",
            "    def create_classifier(self, num_classes: int) -> nn.Sequential:\n",
            "        '''\n",
            "        Creates a sequential classifier head at the very \n",
            "        '''\n",
            "        return nn.Sequential(\n",
            "            nn.AdaptiveAvgPool2d(1),\n",
            "            nn.Flatten(),\n",
            "            nn.LazyLinear(num_classes)\n",
            "        )\n",
            "\n",
            "    def create_block(self, block_type: ResidualBlockType, num_residuals: int, num_channels: int, first_block: bool = False) -> nn.Sequential:\n",
            "        layer = []\n",
            "        for i in range(num_residuals):\n",
            "            if i == 0 and not first_block:\n",
            "                if block_type == ResidualBlockType.BASIC:\n",
            "                    layer.append(ResidualBlock(num_channels, use_stem=True, strides=2))\n",
            "                elif block_type == ResidualBlockType.BOTTLENECK:\n",
            "                    layer.append(ResidualBottleNeck(num_channels, use_stem=True, strides=2))\n",
            "            else:\n",
            "                if block_type == ResidualBlockType.BASIC:\n",
            "                    layer.append(ResidualBlock(num_channels))\n",
            "                elif block_type == ResidualBlockType.BOTTLENECK:\n",
            "                    layer.append(ResidualBottleNeck(num_channels))\n",
            "        return nn.Sequential(*layer)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install torchsummary"
      ],
      "metadata": {
        "id": "a35H8-fHva-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary==1.4.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl6txAfjveKz",
        "outputId": "cd502b71-2b89-41c8-f56b-9e7378250775"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-summary==1.4.5 in /usr/local/lib/python3.7/dist-packages (1.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "XevOmpYxT2iJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the function's parameters\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6qJSyWLT4On",
        "outputId": "10975c73-15b4-46d6-f7cb-ecfe6aa75436"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torchsummary.torchsummary.summary(model: torch.nn.modules.module.Module, input_data: Union[torch.Tensor, torch.Size, Sequence[torch.Tensor], Sequence[Union[int, Sequence[Any], torch.Size]], NoneType] = None, *args: Any, batch_dim: Union[int, NoneType] = 0, branching: bool = True, col_names: Union[Iterable[str], NoneType] = None, col_width: int = 25, depth: int = 3, device: Union[torch.device, NoneType] = None, dtypes: Union[List[torch.dtype], NoneType] = None, verbose: int = 1, **kwargs: Any) -> torchsummary.model_statistics.ModelStatistics>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Transformed CIFAR-10 Data"
      ],
      "metadata": {
        "id": "y-avCoynty9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## transforms.py\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def make_transforms(means: torch.Tensor, std_devs: torch.Tensor) -> Tuple:\n",
        "    '''\n",
        "    Given a tensor of computed means and a tensor of computed standard devations,\n",
        "    return's a tuple containing a train and test transform pipelines\n",
        "    '''\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomCrop(32, padding=2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=means,\n",
        "                             std=std_devs)\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=means,\n",
        "                             std=std_devs)\n",
        "    ])\n",
        "\n",
        "    return train_transforms, test_transforms\n"
      ],
      "metadata": {
        "id": "DgotdoTTtolZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## data.py\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import copy\n",
        "from typing import Tuple, Callable\n",
        "\n",
        "\n",
        "## 2. Prepare to normalize data (the same way for TRAIN and TEST)\n",
        "def summarize_train_data(train_data: datasets.cifar.CIFAR10) -> Tuple[torch.Tensor , torch.Tensor]:\n",
        "    '''Compute means and standard deviations along the R,G,B channel'''\n",
        "    means = train_data.data.mean(axis = (0, 1, 2)) / 255\n",
        "    stds  = train_data.data.std( axis = (0, 1, 2)) / 255\n",
        "    # EACH returns a tensor of shape (3,) = a vector of size 3 (= R,G,B)\n",
        "    return means, stds\n",
        "\n",
        "## 4. Load and custom-partition data\n",
        "def partition_train_data(train_data, valid_ratio):\n",
        "    '''partition TRAIN data into TRAIN and VALID'''\n",
        "\n",
        "    # the partition:len(train_data) == num_valid_examples + num_train_examples\n",
        "    num_valid_examples = int(len(train_data) * valid_ratio)\n",
        "    num_train_examples = len(train_data) - num_valid_examples\n",
        "\n",
        "    train_data, valid_data = \\\n",
        "    data.random_split(train_data, [num_train_examples, num_valid_examples])\n",
        "    \n",
        "    return train_data, copy.deepcopy(valid_data)\n",
        "\n",
        "\n",
        "## 1. through 4.\n",
        "def get_transformed_data(make_transforms: Callable, valid_ratio: float) -> Tuple[\n",
        "    torch.utils.data.dataset.Subset,\n",
        "    torch.utils.data.dataset.Subset,\n",
        "    datasets.cifar.CIFAR10]:\n",
        "    '''\n",
        "    Where transform = augment & normalize\n",
        "    @param: make_transforms (Callable) - how to augment & normalize train and non-train data\n",
        "        (e.g. this function defined in `from src.transforms import make_transforms`)\n",
        "    @param: valid_ratio (float) - the share of train_data that will redesignate as valid_data\n",
        "    '''\n",
        "    \n",
        "    ## 1. Download TRAIN (50K) data\n",
        "    ROOT = '.data'\n",
        "    train_data = datasets.CIFAR10(root = ROOT, train = True, download = True) # len=50K\n",
        "\n",
        "    ## 2. Prepare to normalize data (the same way for TRAIN and TEST)\n",
        "    train_data_means, train_data_stds = summarize_train_data(train_data)\n",
        "\n",
        "    ## 3. Augment TRAIN data; Normalize data (the same way  for TRAIN and TEST)\n",
        "    train_transforms, test_transforms = make_transforms(train_data_means, train_data_stds)\n",
        "\n",
        "    ## 4. Load and custom-partition data\n",
        "\n",
        "    # load TRAIN (50K) and TEST (10K) data\n",
        "    train_data = datasets.CIFAR10(ROOT, train=True,  download=True, transform=train_transforms)\n",
        "    test_data  = datasets.CIFAR10(ROOT, train=False, download=True, transform=test_transforms)\n",
        "\n",
        "    # custom-partition data: TRAIN -> VALID(valid_ratio) & TRAIN(1 - valid_ratio)\n",
        "    train_data, valid_data = partition_train_data(train_data, valid_ratio)\n",
        "\n",
        "    # will transform (= augment & normalize) VALID data the same way as we do TEST data\n",
        "    valid_data.dataset.transform = test_transforms\n",
        "\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "## 5. Data loader\n",
        "def make_data_loaders(\n",
        "    train_data: torch.utils.data.dataset.Subset,\n",
        "    valid_data: torch.utils.data.dataset.Subset, \n",
        "    test_data:  datasets.cifar.CIFAR10,\n",
        "    batch_size: int) -> Tuple[\n",
        "        torch.utils.data.dataloader.DataLoader,\n",
        "        torch.utils.data.dataloader.DataLoader,\n",
        "        torch.utils.data.dataloader.DataLoader]:\n",
        "\n",
        "    # training requires shuffling\n",
        "    train_iterator = \\\n",
        "    torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    valid_iterator = \\\n",
        "    torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    test_iterator = \\\n",
        "    torch.utils.data.DataLoader(test_data,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_iterator, valid_iterator, test_iterator\n"
      ],
      "metadata": {
        "id": "-Ms9zJDPt39a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE  = 256\n",
        "VALID_RATIO = 0.1  # 10% of TRAIN becomes VALID; 90% of TRAIN remains TRAIN"
      ],
      "metadata": {
        "id": "qTN9lDMOuGHQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = \\\n",
        "get_transformed_data(make_transforms = make_transforms, valid_ratio = VALID_RATIO)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYjwnNa0uH7I",
        "outputId": "3be74f6b-051e-4258-bc47-30fb7e0b2cc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = \\\n",
        "make_data_loaders(train_data, valid_data, test_data, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "YEmht1LcuJAg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiate Model; Count Parameters"
      ],
      "metadata": {
        "id": "pP7NftIPuRq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model import ResidualBlockType\n",
        "\n",
        "from src.model import ResNet, StemConfig\n",
        "from src.utils import initialize_parameters, epoch_time\n",
        "\n"
      ],
      "metadata": {
        "id": "9I6FfTE5vEUm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: def \n",
        "# create_block(self, block_type: ResidualBlockType, \n",
        "#                    num_residuals: int, \n",
        "#                    num_channels: int, \n",
        "#                    first_block: bool = False) -> nn.Sequential:\n",
        "model_architecture = (\n",
        "    (ResidualBlockType.BASIC, 1, 128),\n",
        "    (ResidualBlockType.BASIC, 2, 128),\n",
        "    (ResidualBlockType.BASIC, 2, 128),\n",
        "    (ResidualBlockType.BASIC, 2, 128),\n",
        "    (ResidualBlockType.BASIC, 2, 196),\n",
        "    (ResidualBlockType.BASIC, 2, 196),\n",
        ")\n",
        "\n",
        "stem_config = StemConfig(num_channels=128, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "model = ResNet(model_architecture, stem_config=stem_config, output_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPUczIs1uNAh",
        "outputId": "a30b7b76-34af-4285-f7dd-78be2fe918b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "2bb6ZEbzULse"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.rand(256, 3, 32, 32)\n",
        "output = model(input)"
      ],
      "metadata": {
        "id": "0v5EKTTquXVR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1hibgw8UVwy",
        "outputId": "67fc0c29-3b46-45c7-c6c0-de879fa1e65b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "├─Sequential: 1-1                        --\n",
            "|    └─Conv2d: 2-1                       9,728\n",
            "|    └─BatchNorm2d: 2-2                  256\n",
            "|    └─ReLU: 2-3                         --\n",
            "├─Sequential: 1-2                        --\n",
            "|    └─AdaptiveAvgPool2d: 2-4            --\n",
            "|    └─Flatten: 2-5                      --\n",
            "|    └─Linear: 2-6                       1,970\n",
            "├─Sequential: 1-3                        --\n",
            "|    └─Sequential: 2-7                   --\n",
            "|    |    └─ResidualBlock: 3-1           295,680\n",
            "|    └─Sequential: 2-8                   --\n",
            "|    |    └─ResidualBlock: 3-2           312,192\n",
            "|    |    └─ResidualBlock: 3-3           295,680\n",
            "|    └─Sequential: 2-9                   --\n",
            "|    |    └─ResidualBlock: 3-4           312,192\n",
            "|    |    └─ResidualBlock: 3-5           295,680\n",
            "|    └─Sequential: 2-10                  --\n",
            "|    |    └─ResidualBlock: 3-6           312,192\n",
            "|    |    └─ResidualBlock: 3-7           295,680\n",
            "|    └─Sequential: 2-11                  --\n",
            "|    |    └─ResidualBlock: 3-8           597,996\n",
            "|    |    └─ResidualBlock: 3-9           692,664\n",
            "|    └─Sequential: 2-12                  --\n",
            "|    |    └─ResidualBlock: 3-10          731,276\n",
            "|    |    └─ResidualBlock: 3-11          692,664\n",
            "=================================================================\n",
            "Total params: 4,845,850\n",
            "Trainable params: 4,845,850\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "├─Sequential: 1-1                        --\n",
              "|    └─Conv2d: 2-1                       9,728\n",
              "|    └─BatchNorm2d: 2-2                  256\n",
              "|    └─ReLU: 2-3                         --\n",
              "├─Sequential: 1-2                        --\n",
              "|    └─AdaptiveAvgPool2d: 2-4            --\n",
              "|    └─Flatten: 2-5                      --\n",
              "|    └─Linear: 2-6                       1,970\n",
              "├─Sequential: 1-3                        --\n",
              "|    └─Sequential: 2-7                   --\n",
              "|    |    └─ResidualBlock: 3-1           295,680\n",
              "|    └─Sequential: 2-8                   --\n",
              "|    |    └─ResidualBlock: 3-2           312,192\n",
              "|    |    └─ResidualBlock: 3-3           295,680\n",
              "|    └─Sequential: 2-9                   --\n",
              "|    |    └─ResidualBlock: 3-4           312,192\n",
              "|    |    └─ResidualBlock: 3-5           295,680\n",
              "|    └─Sequential: 2-10                  --\n",
              "|    |    └─ResidualBlock: 3-6           312,192\n",
              "|    |    └─ResidualBlock: 3-7           295,680\n",
              "|    └─Sequential: 2-11                  --\n",
              "|    |    └─ResidualBlock: 3-8           597,996\n",
              "|    |    └─ResidualBlock: 3-9           692,664\n",
              "|    └─Sequential: 2-12                  --\n",
              "|    |    └─ResidualBlock: 3-10          731,276\n",
              "|    |    └─ResidualBlock: 3-11          692,664\n",
              "=================================================================\n",
              "Total params: 4,845,850\n",
              "Trainable params: 4,845,850\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLX150ZaXg-H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "num_channels, block_type = 128, ResidualBlockType.BASIC\n",
        "|    └─ReLU: 2-3                         [-1, 128, 32, 32]         --\n",
        "├─Sequential: 1-2                        [-1, 128, 32, 32]         --\n",
        "|    └─Sequential: 2-4                   [-1, 128, 32, 32]         --\n",
        "|    |    └─ResidualBlock: 3-1           [-1, 128, 32, 32]         295,680\n",
        "```\n",
        "\n",
        "```\n",
        "num_channels, block_type = 128, ResidualBlockType.BOTTLENECK\n",
        "|    └─ReLU: 2-3                         [-1, 128, 32, 32]         --\n",
        "├─Sequential: 1-2                        [-1, 128, 32, 32]         --\n",
        "|    └─Sequential: 2-4                   [-1, 128, 32, 32]         --\n",
        "|    |    └─ResidualBottleNeck: 3-1      [-1, 128, 32, 32]         17,984\n",
        "```\n",
        "```\n",
        "num_channels, block_type = 128*4, ResidualBlockType.BOTTLENECK\n",
        "|    └─ReLU: 2-3                         [-1, 512, 32, 32]         --\n",
        "├─Sequential: 1-2                        [-1, 512, 32, 32]         --\n",
        "|    └─Sequential: 2-4                   [-1, 512, 32, 32]         --\n",
        "|    |    └─ResidualBottleNeck: 3-1      [-1, 512, 32, 32]         280,832\n",
        "```"
      ],
      "metadata": {
        "id": "45fP6QSsXgpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "num_channels1, num_channels2, block_type = 64, 128*4, ResidualBlockType.BOTTLENECK\n",
        "                                         [-1, 3, 32, 32]           --\n",
        "|    └─Conv2d: 2-1                                                 9,728\n",
        "                                         [-1, 128, 32, 32]\n",
        "|    └─BatchNorm2d: 2-2                                            256\n",
        "                                         [-1, 128, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-1                                17,984\n",
        "                                         [-1, 128, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-2                                297,728\n",
        "                                         [-1, 512, 16, 16]\n",
        "|    └─AdaptiveAvgPool2d: 2-6                                      --\n",
        "                                         [-1, 512, 1, 1]\n",
        "```\n",
        "```\n",
        "num_channels1, num_channels2, block_type = 64, 128*4, ResidualBlockType.BOTTLENECK\n",
        "model_architecture = (\n",
        "    (block_type, 2, num_channels1),\n",
        "    (block_type, 2, num_channels2)\n",
        ")                                        [-1, 3, 32, 32]           --\n",
        "|    └─Conv2d: 2-1                                                 4,864\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    └─BatchNorm2d: 2-2                                            128\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-1                                4,640\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-2                                4,640\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-3                                256,768\n",
        "                                         [-1, 512, 16, 16]\n",
        "|    |    └─ResidualBottleNeck: 3-4                                280,832\n",
        "                                         [-1, 512, 16, 16]\n",
        "|    └─AdaptiveAvgPool2d: 2-6                                      --\n",
        "                                         [-1, 512, 1, 1]\n",
        "```\n",
        "```\n",
        "num_channels1, num_channels2, block_type = 64, 128, ResidualBlockType.BASIC\n",
        "model_architecture = (\n",
        "    (block_type, 2, num_channels1),\n",
        "    (block_type, 2, num_channels2)\n",
        ")\n",
        "├─Sequential: 1-1                        [-1, 3, 32, 32]           --\n",
        "|    └─Conv2d: 2-1                                                 4,864\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    └─BatchNorm2d: 2-2                                            128\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBlock: 3-1                                     74,112\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBlock: 3-2                                     74,112\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBlock: 3-3                                     230,272\n",
        "                                         [-1, 128, 16, 16]\n",
        "|    |    └─ResidualBlock: 3-4                                     295,680\n",
        "                                         [-1, 128, 16, 16]\n",
        "|    └─AdaptiveAvgPool2d: 2-6                                      --\n",
        "                                         [-1, 128, 1, 1]\n",
        "```\n",
        "```\n",
        "num_channels1, num_channels2, block_type = 64, 128, ResidualBlockType.BOTTLENECK\n",
        "\n",
        "model_architecture = (\n",
        "    (block_type, 2, num_channels1),\n",
        "    (block_type, 2, num_channels2)\n",
        ")\n",
        "                                         [-1, 3, 32, 32]\n",
        "|    └─Conv2d: 2-1                                 4,864\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    └─BatchNorm2d: 2-2                            128\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-1                4,640\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-2                4,640\n",
        "                                         [-1, 64, 32, 32]\n",
        "|    |    └─ResidualBottleNeck: 3-3               24,256\n",
        "                                         [-1, 128, 16, 16]\n",
        "|    |    └─ResidualBottleNeck: 3-4               17,984\n",
        "                                         [-1, 128, 16, 16]\n",
        "|    └─AdaptiveAvgPool2d: 2-6                       --\n",
        "                                         [-1, 128, 1, 1]\n",
        "```\n",
        "\n",
        "\n",
        "Conclusion:\n",
        "```\n",
        "[-1,  64, 32, 32] --ResidualBlock     ( 74,112 params)--> [-1,  64, 32, 32]\n",
        "[-1,  64, 32, 32] --ResidualBottleNeck(  4,640 params)--> [-1,  64, 32, 32]\n",
        "\n",
        "\n",
        "[-1,  64, 32, 32] --ResidualBlock     (230,272 parmas)--> [-1, 128, 16, 16]\n",
        "[-1,  64, 32, 32] --ResidualBottleNeck( 24,256 params)--> [-1, 128, 16, 16]\n",
        "[-1,  64, 32, 32] --ResidualBottleNeck(256,768 params)--> [-1, 512, 16, 16]\n",
        "\n",
        "[-1, 128, 16, 16] --ResidualBlock     (295,680 params)--> [-1, 128, 16, 16]\n",
        "[-1, 128, 16, 16] --ResidualBottleNeck( 17,984 params)--> [-1, 128, 16, 16]\n",
        "[-1, 512, 16, 16] --ResidualBottleNeck(280,832 parmas)--> [-1, 512, 16, 16]\n",
        "```"
      ],
      "metadata": {
        "id": "_0Xj6iIsZxBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels1, num_channels2, block_type = 64, 128, ResidualBlockType.BOTTLENECK\n",
        "\n",
        "stem_config = StemConfig(num_channels=num_channels1, \n",
        "                         kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "model_architecture = (\n",
        "    (block_type, 2, num_channels1),\n",
        "    (block_type, 2, num_channels2)\n",
        ")\n",
        "\n",
        "model = ResNet(model_architecture, stem_config=stem_config, output_size=10)\n",
        "\n",
        "input = torch.rand(256, 3, 32, 32)\n",
        "output = model(input)\n",
        "\n",
        "summary(model, (3,32,32), verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvy-BHViUmWQ",
        "outputId": "a12d9a19-1ec1-40d5-af52-322a9086919f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
              "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          4,864\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
              "|    └─ReLU: 2-3                         [-1, 64, 32, 32]          --\n",
              "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
              "|    └─Sequential: 2-4                   [-1, 64, 32, 32]          --\n",
              "|    |    └─ResidualBottleNeck: 3-1      [-1, 64, 32, 32]          4,640\n",
              "|    |    └─ResidualBottleNeck: 3-2      [-1, 64, 32, 32]          4,640\n",
              "|    └─Sequential: 2-5                   [-1, 128, 16, 16]         --\n",
              "|    |    └─ResidualBottleNeck: 3-3      [-1, 128, 16, 16]         24,256\n",
              "|    |    └─ResidualBottleNeck: 3-4      [-1, 128, 16, 16]         17,984\n",
              "├─Sequential: 1-3                        [-1, 10]                  --\n",
              "|    └─AdaptiveAvgPool2d: 2-6            [-1, 128, 1, 1]           --\n",
              "|    └─Flatten: 2-7                      [-1, 128]                 --\n",
              "|    └─Linear: 2-8                       [-1, 10]                  1,290\n",
              "==========================================================================================\n",
              "Total params: 57,802\n",
              "Trainable params: 57,802\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 26.05\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 6.13\n",
              "Params size (MB): 0.22\n",
              "Estimated Total Size (MB): 6.36\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels = 200\n",
        "\n",
        "model_architecture = (\n",
        "    (ResidualBlockType.BOTTLENECK, 1, num_channels),\n",
        ")\n",
        "\n",
        "stem_config = StemConfig(num_channels=num_channels, \n",
        "                         kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "model = ResNet(model_architecture, stem_config=stem_config, output_size=10)\n",
        "\n",
        "input = torch.rand(256, 3, 32, 32)\n",
        "output = model(input)\n",
        "\n",
        "summary(model, (3,32,32), verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwDZstoWU0j7",
        "outputId": "6115920d-0945-43f6-b086-3671fd7645a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 200, 32, 32]         --\n",
              "|    └─Conv2d: 2-1                       [-1, 200, 32, 32]         15,200\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 200, 32, 32]         400\n",
              "|    └─ReLU: 2-3                         [-1, 200, 32, 32]         --\n",
              "├─Sequential: 1-2                        [-1, 200, 32, 32]         --\n",
              "|    └─Sequential: 2-4                   [-1, 200, 32, 32]         --\n",
              "|    |    └─ResidualBottleNeck: 3-1      [-1, 200, 32, 32]         43,400\n",
              "├─Sequential: 1-3                        [-1, 10]                  --\n",
              "|    └─AdaptiveAvgPool2d: 2-5            [-1, 200, 1, 1]           --\n",
              "|    └─Flatten: 2-6                      [-1, 200]                 --\n",
              "|    └─Linear: 2-7                       [-1, 10]                  2,010\n",
              "==========================================================================================\n",
              "Total params: 61,010\n",
              "Trainable params: 61,010\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 59.03\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 7.81\n",
              "Params size (MB): 0.23\n",
              "Estimated Total Size (MB): 8.06\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhuaE0qCVXWL"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}