{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5a2OcE_GwrT"
      },
      "outputs": [],
      "source": [
        "# !pip install -U \"git+https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\"\n",
        "\n",
        "!git clone -b alex \"https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\"\n",
        "!cp -r /content/csgy6953_DeepLearning_Midterm/src/ .\n",
        "# !cp csgy6953_DeepLearning_Midterm/requirements.txt ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M1qpHXBNk1w",
        "outputId": "51322ebb-a4b0-4488-b8a9-12c0b7b2c6ac"
      },
      "outputs": [],
      "source": [
        "# \n",
        "# !pip install -r requirements.txt\n",
        "!pip install wandb\n",
        "!wandb login \"996181dd165ce17c309c3d027297e4ed8952f4ec\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ow3lduSvGwrU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import time\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJaOta3cmQwI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c2CF9rXbGwrU"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "0075dc0c3cdd4930a593cb78aae2cdc7"
          ]
        },
        "id": "EahkXKUGNk1x",
        "outputId": "887df171-2e9d-4ee4-fa0a-8948336eb1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from src.data import get_transformed_data, make_data_loaders\n",
        "from src.transforms import make_transforms, make_auto_transforms\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "valid_ratio = 0.1\n",
        "train_data, valid_data, test_data = (\n",
        "    get_transformed_data(\n",
        "        make_transforms = make_auto_transforms, \n",
        "        valid_ratio = valid_ratio\n",
        "    )\n",
        ")\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = (\n",
        "    make_data_loaders(\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        test_data,\n",
        "        batch_size\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfPJNbhPGwrW"
      },
      "source": [
        "**Define our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsPprgn5GwrW",
        "outputId": "136c3105-0981-4920-e577-33b0fb3f2c05"
      },
      "outputs": [],
      "source": [
        "from src.model import ResNet, StemConfig, ResidualBlockType\n",
        "from src.utils import initialize_parameters, epoch_time\n",
        "\n",
        "architecture = [\n",
        "    (ResidualBlockType.BOTTLENECK, 2, 128, 0.25),\n",
        "    (ResidualBlockType.BOTTLENECK, 6, 256, 0.25),\n",
        "    (ResidualBlockType.BOTTLENECK, 6, 512, 0.25),\n",
        "    (ResidualBlockType.BOTTLENECK, 2, 1024, 0.25),\n",
        "]\n",
        "\n",
        "config = StemConfig(num_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "model = ResNet(architecture, stem_config=config, output_size=10, use_bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QDYsBaXalMYo"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "path = \"/content/drive/MyDrive/School/Tandon MSCS/Classes/CS-GY 6953: Deep Learning/midterm/\"\n",
        "# path = \"/content/drive/MyDrive/Colab Notebooks/midterm/\"\n",
        "project_name = \"alex_b512_drop__autoaug__bias__bottleb__adamW_cyclelr_arch1\"\n",
        "file_path = path + project_name\n",
        "\n",
        "model_file = Path(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-teLbU72GwrX"
      },
      "source": [
        "Need to run a dummy set of data to initialize the lazy modules before we can use torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GtRvQ7y_GwrX",
        "outputId": "1c4331fa-a723-4d05-b574-c5d138931179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 10])\n"
          ]
        }
      ],
      "source": [
        "if model_file.exists() and model_file.is_file():\n",
        "  # load our previously trained model\n",
        "  model.load_state_dict(torch.load(model_file))\n",
        "  model = model.to(device)\n",
        "else:\n",
        "  # intialize a new model\n",
        "  inputs = torch.empty((batch_size, 3, 32, 32))\n",
        "  inputs.normal_()\n",
        "  model = model.to(device)\n",
        "  y = model(inputs.to(device))\n",
        "  print(y.size())\n",
        "\n",
        "  model.apply(initialize_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjqTh-mhGwrX",
        "outputId": "1e3e4d65-77e3-450c-d07f-24d5ce74b864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 4,915,082 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "from src.utils import count_parameters\n",
        "\n",
        "num_params, grad_params = count_parameters(model)\n",
        "print(f\"There are {grad_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN5uGCn-GwrX"
      },
      "outputs": [],
      "source": [
        "from src.engine import train_one_epoch, evaluate\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "best_loss = float('inf')\n",
        "EPOCHS  = 100\n",
        "learning_rate = 0.01\n",
        "max_lr = 0.5\n",
        "base_lr = 0.0001\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=learning_rate, cycle_momentum=False)\n",
        "\n",
        "if model_file.is_file():\n",
        "  # if we loaded a previously saved iteration, we want to get the current\n",
        "  # best loss otherwise we could overwrite our save with a worse model\n",
        "  loss, acc = evaluate(model.to(device), test_iterator, criterion, device)\n",
        "  best_loss = loss\n",
        "  print(f\"Prevous best loss: {loss:.4f}, acc: {acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "A0OpN8SWNk1z",
        "outputId": "bcc61ccd-e8b8-4f7f-dcc9-c685e24cb48b"
      },
      "outputs": [],
      "source": [
        "# setup wandb logging\n",
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project='ResNet_5M',\n",
        "    name=project_name,\n",
        "    entity=\"dlf22_mini_project\",\n",
        "    config={\n",
        "        \"learning_rate\":learning_rate,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"architecture\": architecture,\n",
        "        \"grad_params\": grad_params,\n",
        "        \"lr_schedule\": f\"CyclicLR_base_{base_lr}_max_{max_lr}\"\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS1DEX_fGwrX",
        "outputId": "55d38936-d369-4167-867c-e888b92a43dd"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    start = time.time()\n",
        "\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    train_loss, train_acc = train_one_epoch(model, train_iterator, criterion, optimizer, device)\n",
        "    train_mins, train_secs = epoch_time(start, time.time())\n",
        "\n",
        "    wandb.log({\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"epoch\": epoch\n",
        "    })\n",
        "\n",
        "    print(f\"\\tTrain elapsed: {train_mins}:{train_secs}, loss: {train_loss:.4f}, acc: {train_acc * 100:.2f}%\")\n",
        "\n",
        "    start = time.time()\n",
        "    val_loss, val_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    val_mins, val_secs = epoch_time(start, time.time())\n",
        "\n",
        "    wandb.log({\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"epoch\": epoch,\n",
        "    })\n",
        "    \n",
        "    scheduler.step()\n",
        "    print(f\"\\tValidation elapsed: {val_mins}:{val_secs}, loss: {val_loss:.4f}, acc: {val_acc * 100:.2f}%\")\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txl2I40ZGwrX"
      },
      "source": [
        "## Evaluate the Model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io_QMFwgGwrX"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(file_path))\n",
        "test_loss, test_acc = evaluate(model.to(device), test_iterator, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_acc\": test_acc,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVyNopm6I9g-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b53f36c18b1007b71a362ee7be890264880ad87693ab57d2c5b205b6d4469eb2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
