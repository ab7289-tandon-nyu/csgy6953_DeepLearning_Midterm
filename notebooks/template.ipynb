{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5a2OcE_GwrT",
        "outputId": "4904f2e5-374b-4622-9316-4dc9d615aca1"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"git+https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# connect to our wandb project\n",
        "!pip install wandb\n",
        "!wandb login \"API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow3lduSvGwrU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJaOta3cmQwI",
        "outputId": "81ddc041-d1ee-410d-ab80-e9a75890b761"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2CF9rXbGwrU"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxwCl4lcGwrW"
      },
      "outputs": [],
      "source": [
        "from src.data import get_transformed_data, make_data_loaders\n",
        "from src.transforms import make_transforms\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "valid_ratio = 0.1\n",
        "\n",
        "train_data, valid_data, test_data = (\n",
        "    get_transformed_data(\n",
        "        make_transforms = make_transforms,\n",
        "        valid_ratio = valid_ratio\n",
        "    )\n",
        ")\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = (\n",
        "    make_data_loaders(\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        test_data,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfPJNbhPGwrW"
      },
      "source": [
        "**Define our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsPprgn5GwrW",
        "outputId": "3303861d-2a4a-4df6-d556-7874b6d1ccec"
      },
      "outputs": [],
      "source": [
        "from src.model import ResNet, StemConfig\n",
        "from src.utils import initialize_parameters, epoch_time\n",
        "\n",
        "model_architecture = (\n",
        "    (1, 128),\n",
        "    (2, 128),\n",
        "    (2, 128),\n",
        "    (2, 128),\n",
        "    (2, 196),\n",
        "    (2, 196),\n",
        ")\n",
        "\n",
        "stem_config = StemConfig(num_channels=128, kernel_size=5, stride=1, padding=2)\n",
        "model = ResNet(model_architecture, stem_config=stem_config, output_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "path = \"/TODO/\"\n",
        "file_path = path + \"TODO.pt\"\n",
        "\n",
        "model_file = Path(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-teLbU72GwrX"
      },
      "source": [
        "Need to run a dummy set of data to initialize the lazy modules before we can use torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtRvQ7y_GwrX",
        "outputId": "c338dc30-247a-4b97-94ea-b8baf79c6633"
      },
      "outputs": [],
      "source": [
        "if model_file.exists() and model_file.is_file():\n",
        "  print(\"loading model\")\n",
        "  # load our previously trained model\n",
        "  model.load_state_dict(torch.load(model_file))\n",
        "  model = model.to(device)\n",
        "else:\n",
        "  # intialize a new model\n",
        "  print(\"init new model parameters\")\n",
        "  inputs = torch.empty((BATCH_SIZE, 3, 32, 32))\n",
        "  inputs.normal_()\n",
        "  model = model.to(device)\n",
        "  y = model(inputs.to(device))\n",
        "  print(y.size())\n",
        "\n",
        "  model.apply(initialize_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjqTh-mhGwrX",
        "outputId": "3307be6b-9824-43d1-93f8-cac0d22ab58e"
      },
      "outputs": [],
      "source": [
        "from src.utils import count_parameters\n",
        "\n",
        "num_params, grad_params = count_parameters(model)\n",
        "print(f\"There are {grad_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN5uGCn-GwrX"
      },
      "outputs": [],
      "source": [
        "from src.engine import train_one_epoch, evaluate\n",
        "\n",
        "best_loss = float('inf')\n",
        "EPOCHS  = 100\n",
        "learning_rate = 1e-3\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "if model_file.is_file():\n",
        "  # if we loaded a previously saved iteration, we want to get the current\n",
        "  # best loss otherwise we could overwrite our save with a worse model\n",
        "  loss, acc = evaluate(model.to(device), test_iterator, criterion, device)\n",
        "  best_loss = loss\n",
        "  print(f\"Prevous best loss: {loss:.4f}, acc: {acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup wandb logging\n",
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project='ResNet_5M',\n",
        "    name=\"resnet_alex_49m_dropout\",\n",
        "    entity=\"dlf22_mini_project\",\n",
        "    config={\n",
        "        \"learning_rate\":learning_rate,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"architecture\": model_architecture,\n",
        "        \"avg_pool\": 4,\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS1DEX_fGwrX",
        "outputId": "8dd0711b-60f5-4a91-db3b-baf76c54de2c"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    start = time.time()\n",
        "\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    train_loss, train_acc = train_one_epoch(model, train_iterator, criterion, optimizer, device)\n",
        "    train_mins, train_secs = epoch_time(start, time.time())\n",
        "\n",
        "    wandb.log({\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"epoch\": epoch\n",
        "    })\n",
        "\n",
        "    print(f\"\\tTrain elapsed: {train_mins}:{train_secs}, loss: {train_loss:.4f}, acc: {train_acc * 100:.2f}%\")\n",
        "\n",
        "    start = time.time()\n",
        "    val_loss, val_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    val_mins, val_secs = epoch_time(start, time.time())\n",
        "\n",
        "    wandb.log({\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"epoch\": epoch,\n",
        "    })\n",
        "\n",
        "    print(f\"\\tValidation elapsed: {val_mins}:{val_secs}, loss: {val_loss:.4f}, acc: {val_acc * 100:.2f}%\")\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txl2I40ZGwrX"
      },
      "source": [
        "## Evaluate the Model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io_QMFwgGwrX",
        "outputId": "1c3d6a85-24cb-46a9-8cf3-eb839ae6fdba"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(file_path))\n",
        "test_loss, test_acc = evaluate(model.to(device), test_iterator, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_acc\": test_acc,\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1f47d77051f6b3ff9692dd9abb1762c48ba70321fbafb2dfb079395901beb4e2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
