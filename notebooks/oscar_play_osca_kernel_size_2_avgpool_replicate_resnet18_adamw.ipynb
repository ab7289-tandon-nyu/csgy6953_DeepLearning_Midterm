{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm/blob/oscar2/notebooks/oscar_play_osca_kernel_size_2_avgpool_replicate_resnet18_adamw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HqUIrHzYpEF"
      },
      "source": [
        "# Clone, Install Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD8cBXZ_YpEJ"
      },
      "source": [
        "## Timestamp this run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4MnxcGBFYpEL",
        "outputId": "1b2d05a2-3e19-49fc-c04e-5db746a1d8c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (2022.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfovHN-sl04P",
        "outputId": "66351b36-d765-4f71-8985-c0c66fb13a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/19(Sat)_14:42:24\n"
          ]
        }
      ],
      "source": [
        "# reference: https://www.programiz.com/python-programming/datetime/current-time\n",
        "\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "print(datetime.now(pytz.timezone('America/New_York')).strftime('%m/%d(%a)_%H:%M:%S'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEg6gGl4gdFv"
      },
      "source": [
        "# Wandb install, login, import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrgALvYPgMBy",
        "outputId": "ebf48db0-9e99-4b63-a67c-4bab71291ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.5)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.29)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBNArx2fgf-v",
        "outputId": "ccf5ae4a-5f82-487b-b75f-abb90c355ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login \"6f19b1e6735ebc69af24f18d5b426262416027fb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MP8Tcl1ogjVP"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFOQTotOdDmI"
      },
      "source": [
        "## Torchsummary Install, Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "293u_6mjdMDE",
        "outputId": "54bc9610-e3cb-498b-eea1-02091678f142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-summary==1.4.5 in /usr/local/lib/python3.7/dist-packages (1.4.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-summary==1.4.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8mq4tcWdOSP",
        "outputId": "5af446c5-26d0-4ac6-8e6c-945c15e4da46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torchsummary.torchsummary.summary(model: torch.nn.modules.module.Module, input_data: Union[torch.Tensor, torch.Size, Sequence[torch.Tensor], Sequence[Union[int, Sequence[Any], torch.Size]], NoneType] = None, *args: Any, batch_dim: Union[int, NoneType] = 0, branching: bool = True, col_names: Union[Iterable[str], NoneType] = None, col_width: int = 25, depth: int = 3, device: Union[torch.device, NoneType] = None, dtypes: Union[List[torch.dtype], NoneType] = None, verbose: int = 1, **kwargs: Any) -> torchsummary.model_statistics.ModelStatistics>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bbnVuzegpXs"
      },
      "source": [
        "## Clone team's code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rSPl_TQsiRgl"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/csgy6953_DeepLearning_Midterm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw2LzDqIgoQt",
        "outputId": "67068905-2335-4442-f3f9-0ecd5c14363a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'csgy6953_DeepLearning_Midterm'...\n",
            "remote: Enumerating objects: 658, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 658 (delta 70), reused 64 (delta 43), pack-reused 507\u001b[K\n",
            "Receiving objects: 100% (658/658), 190.67 KiB | 1.44 MiB/s, done.\n",
            "Resolving deltas: 100% (421/421), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b config_kernel_size_on_updated_main \"https://github.com/ab7289-tandon-nyu/csgy6953_DeepLearning_Midterm.git\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_buBR1H1YpEU"
      },
      "source": [
        "if running on Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "17_B3oo1glfe"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/csgy6953_DeepLearning_Midterm/src/ ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmnH6onXYpEV"
      },
      "source": [
        "if running on Amazon SageMaker Studio Lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m2NARt3GYpEV"
      },
      "outputs": [],
      "source": [
        "# !cp -r csgy6953_DeepLearning_Midterm/src/ ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/model.py"
      ],
      "metadata": {
        "id": "8aaPKvBWaUtW",
        "outputId": "9aa19cb4-9a15-4af7-e531-93d294be5c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from enum import Enum\n",
            "from typing import List, Optional, Tuple\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "\n",
            "class ResidualBlockType(Enum):\n",
            "    \"\"\"\n",
            "    Enum class to represent the residual block type for ResNet\n",
            "    \"\"\"\n",
            "\n",
            "    BASIC = 0\n",
            "    BOTTLENECK = 1\n",
            "\n",
            "\n",
            "class LayerType(Enum):\n",
            "    \"\"\"\n",
            "    Enum class to represent layer within for ResidualBlock and for BottleneckResidualBlock\n",
            "    \"\"\"\n",
            "\n",
            "    # Disambiguation: here \"layer\" refers to the individual layer within a block,\n",
            "    # not a \"residual layer\" containing one or more blocks\n",
            "    CONV = 0\n",
            "\n",
            "\n",
            "class LayerLoc(Enum):\n",
            "    \"\"\"\n",
            "    Enum class to represent a layer's location within a block\n",
            "    \"\"\"\n",
            "\n",
            "    MAIN_BLOCK_CONV1 = 0\n",
            "    MAIN_BLOCK_CONV2 = 1\n",
            "    MAIN_BLOCK_CONV3 = 2\n",
            "\n",
            "    SHORTCUT_IDENTITY = 6   # identity\n",
            "    SHORTCUT_CONV_STEM = 7\n",
            "\n",
            "\n",
            "def generate_layer(\n",
            "    block_type: ResidualBlockType,\n",
            "    layer_type: LayerType, \n",
            "    layer_loc: LayerLoc, # position of this layer within the block starting from index 1 \n",
            "    num_channels: int,\n",
            "    main_block_kernel_size: int,\n",
            "    strides: int = 1,\n",
            "    factor: int = 4,\n",
            "    use_bias: bool = False,\n",
            "):\n",
            "    \"\"\"\n",
            "    Returns a layer with the most appropriate parameters such as padding \n",
            "    \"\"\"\n",
            "    if block_type == ResidualBlockType.BASIC:\n",
            "        if layer_type == LayerType.CONV:\n",
            "\n",
            "            if main_block_kernel_size == 3:\n",
            "                layer_locator = {\n",
            "                    LayerLoc.MAIN_BLOCK_CONV1: nn.LazyConv2d(\n",
            "                        num_channels,\n",
            "                        kernel_size=3, padding=1, # ResidualBlock.conv1\n",
            "                        stride=strides, bias=use_bias\n",
            "                        ), \n",
            "                     LayerLoc.MAIN_BLOCK_CONV2: nn.LazyConv2d(\n",
            "                        num_channels,\n",
            "                        kernel_size=3, padding=1, # ResidualBlock.conv2\n",
            "                        bias=use_bias\n",
            "                        ),\n",
            "                     LayerLoc.SHORTCUT_IDENTITY: nn.Identity(),\n",
            "                     LayerLoc.SHORTCUT_CONV_STEM: nn.LazyConv2d(\n",
            "                        num_channels, \n",
            "                        kernel_size=1, stride=strides, # ResidualBlock.conv_stem\n",
            "                        bias=use_bias\n",
            "                        )\n",
            "                    }\n",
            "            \n",
            "            # # partial solution 1:\n",
            "            # # fatal issue: when input is [256,1,1], MUST pad in order to apply 2x2 kernel\n",
            "            # if main_block_kernel_size == 2:\n",
            "            #     layer_locator = {\n",
            "            #         LayerLoc.MAIN_BLOCK_CONV1: nn.LazyConv2d(\n",
            "            #             num_channels,\n",
            "            #             kernel_size=2, padding=1, # ResidualBlock.conv1\n",
            "            #             stride=strides, bias=use_bias\n",
            "            #             ), \n",
            "            #          LayerLoc.MAIN_BLOCK_CONV2: nn.LazyConv2d(\n",
            "            #             num_channels,\n",
            "            #             kernel_size=2, padding=0, # ResidualBlock.conv2\n",
            "            #             bias=use_bias\n",
            "            #             ),\n",
            "            #          LayerLoc.SHORTCUT_IDENTITY: nn.Identity(),\n",
            "            #          LayerLoc.SHORTCUT_CONV_STEM: nn.LazyConv2d(\n",
            "            #             num_channels, \n",
            "            #             kernel_size=1, stride=strides, # ResidualBlock.conv_stem\n",
            "            #             bias=use_bias\n",
            "            #             )\n",
            "            #         }\n",
            "            \n",
            "            # partial solution 3:\n",
            "            if main_block_kernel_size == 2:\n",
            "                layer_locator = {\n",
            "                    LayerLoc.MAIN_BLOCK_CONV1: nn.Sequential(\n",
            "                        nn.LazyConv2d(\n",
            "                            num_channels,\n",
            "                            kernel_size=2, padding=1, # ResidualBlock.conv1\n",
            "                            stride=strides, bias=use_bias\n",
            "                            ), # result: image size += 1\n",
            "                        nn.AvgPool2d(\n",
            "                            kernel_size=2, stride=1\n",
            "                            ) # result: image size -= 1\n",
            "                        ),\n",
            "                     LayerLoc.MAIN_BLOCK_CONV2: nn.Sequential(\n",
            "                        nn.LazyConv2d(\n",
            "                            num_channels,\n",
            "                            kernel_size=2, padding=1, # ResidualBlock.conv2\n",
            "                            bias=use_bias\n",
            "                            ), # result: image size += 1\n",
            "                        nn.AvgPool2d(\n",
            "                            kernel_size=2, stride=1\n",
            "                            ) # result: image size -= 1\n",
            "                        ),\n",
            "                     LayerLoc.SHORTCUT_IDENTITY: nn.Identity(),\n",
            "                     LayerLoc.SHORTCUT_CONV_STEM: nn.LazyConv2d(\n",
            "                        num_channels, \n",
            "                        kernel_size=1, stride=strides, # ResidualBlock.conv_stem\n",
            "                        bias=use_bias\n",
            "                        )\n",
            "                    }\n",
            "            \n",
            "    if block_type == ResidualBlockType.BOTTLENECK:\n",
            "        if layer_type == LayerType.CONV:\n",
            "\n",
            "            if main_block_kernel_size == 3:\n",
            "                layer_locator = {\n",
            "                    LayerLoc.MAIN_BLOCK_CONV1: nn.LazyConv2d(\n",
            "                        num_channels // factor,\n",
            "                        kernel_size=1, padding=0, # BottleneckResidualBlock.conv1\n",
            "                        bias=use_bias\n",
            "                        ), \n",
            "                    LayerLoc.MAIN_BLOCK_CONV2: nn.LazyConv2d(\n",
            "                        num_channels // factor,\n",
            "                        kernel_size=3, padding=1, stride=strides, # BottleneckResidualBlock.conv2\n",
            "                        bias=use_bias\n",
            "                        ),\n",
            "                    LayerLoc.MAIN_BLOCK_CONV3: nn.LazyConv2d(\n",
            "                        num_channels, \n",
            "                        kernel_size=1, padding=0, # BottleneckResidualBlock.conv3\n",
            "                        bias=use_bias\n",
            "                        ),\n",
            "                    LayerLoc.SHORTCUT_IDENTITY: nn.Identity(),\n",
            "                    LayerLoc.SHORTCUT_CONV_STEM: nn.LazyConv2d(\n",
            "                        num_channels, \n",
            "                        kernel_size=1, stride=strides, # BottleneckResidualBlock.conv_stem\n",
            "                        bias=use_bias\n",
            "                        )\n",
            "                    }\n",
            "    return layer_locator[layer_loc]\n",
            "    \n",
            "\n",
            "class ResidualBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    Class representing a convolutional residual block\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        num_channels: int,\n",
            "        use_stem: bool = False,\n",
            "        strides: int = 1,\n",
            "        dropout: Optional[float] = None,\n",
            "        use_bias: bool = False,\n",
            "        main_block_kernel_size: int = 3\n",
            "    ):\n",
            "        \"\"\"\n",
            "        Creates a new instance of a Residual Block\n",
            "        @param: num_channels (int) - the number of output channels for all convolutions in\n",
            "            the block\n",
            "        @param: use_stem (bool) - whether a 1x1 convolution is needed to downsample the\n",
            "            residual\n",
            "        @param: strides (int) - the number of strides to use in the convolutions, defaults to 1\n",
            "        @param: dropout (float) - if present, adds a dropout between the hidden layers\n",
            "        \"\"\"\n",
            "        super().__init__()\n",
            "        self.num_channels = num_channels\n",
            "        self.use_stem = use_stem\n",
            "        self.strides = strides\n",
            "\n",
            "        self.dropout = nn.Dropout(dropout) if dropout is not None else None\n",
            "        self.conv1 = generate_layer(\n",
            "            block_type = ResidualBlockType.BASIC,\n",
            "            layer_type = LayerType.CONV,\n",
            "            layer_loc = LayerLoc.MAIN_BLOCK_CONV1,\n",
            "            num_channels = num_channels,\n",
            "            main_block_kernel_size = main_block_kernel_size,\n",
            "            strides = strides,\n",
            "            use_bias = use_bias,\n",
            "        )\n",
            "        self.conv2 = generate_layer(\n",
            "            block_type = ResidualBlockType.BASIC,\n",
            "            layer_type = LayerType.CONV,\n",
            "            layer_loc = LayerLoc.MAIN_BLOCK_CONV2,\n",
            "            num_channels = num_channels,\n",
            "            main_block_kernel_size = main_block_kernel_size,\n",
            "            use_bias = use_bias,\n",
            "        )\n",
            "        self.relu = nn.ReLU(inplace=True)\n",
            "        self.out = nn.ReLU(inplace=True)\n",
            "        self.bn1 = nn.LazyBatchNorm2d()\n",
            "        self.bn2 = nn.LazyBatchNorm2d()\n",
            "\n",
            "        self.identity = None\n",
            "        self.conv_stem = None\n",
            "        if use_stem:\n",
            "            self.conv_stem = generate_layer(\n",
            "                block_type = ResidualBlockType.BASIC,\n",
            "                layer_type = LayerType.CONV,\n",
            "                layer_loc = LayerLoc.SHORTCUT_CONV_STEM,\n",
            "                num_channels = num_channels, \n",
            "                main_block_kernel_size = main_block_kernel_size,\n",
            "                strides = strides,\n",
            "                use_bias = use_bias\n",
            "            )\n",
            "        else:\n",
            "            self.identity = generate_layer(\n",
            "                block_type = ResidualBlockType.BASIC,\n",
            "                layer_type = LayerType.CONV,\n",
            "                layer_loc = LayerLoc.SHORTCUT_IDENTITY,\n",
            "                num_channels = num_channels,\n",
            "                main_block_kernel_size = main_block_kernel_size\n",
            "            )\n",
            "\n",
            "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
            "        shortcut = inputs\n",
            "\n",
            "        x = self.relu(self.bn1(self.conv1(inputs)))\n",
            "        if self.dropout is not None:\n",
            "            x = self.dropout(x)\n",
            "        x = self.bn2(self.conv2(x))\n",
            "        \n",
            "        if self.use_stem:\n",
            "            # downsample skip connection\n",
            "            shortcut = self.conv_stem(shortcut)\n",
            "        else:\n",
            "            shortcut = self.identity(shortcut)\n",
            "\n",
            "        # add in skip connection\n",
            "        x += shortcut\n",
            "        return self.out(x)\n",
            "\n",
            "\n",
            "class BottleneckResidualBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    Class representing a convolutional residual block with a bottleneck\n",
            "    This class was built with reference to:\n",
            "    https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        num_channels: int,\n",
            "        use_stem: bool = False,\n",
            "        strides: int = 1,\n",
            "        factor: int = 4,\n",
            "        dropout: Optional[float] = None,\n",
            "        use_bias: bool = False,\n",
            "    ):\n",
            "        \"\"\"\n",
            "        Creates a new instance of a Residual BottleNeck Block\n",
            "        @param: num_channels (int) - the number of output channels for all convolutions in the block\n",
            "        @param: use_stem (bool) - whether a 1x1 convolution is needed to downsample the residual\n",
            "        @param: strides (int) - the number of strides to use in the convolutions, defaults to 1\n",
            "        @param: factor (int) - the factor by which the input channels will be reduced for the bottleneck\n",
            "        @param: dropout (float) - if present, adds a dropout between the hidden layers\n",
            "        \"\"\"\n",
            "        super().__init__()\n",
            "        self.num_channels = num_channels\n",
            "        self.use_stem = use_stem\n",
            "        self.strides = strides\n",
            "        self.factor = factor\n",
            "        self.dropout1 = nn.Dropout(dropout) if dropout is not None else None\n",
            "        self.dropout2 = nn.Dropout(dropout) if dropout is not None else None\n",
            "\n",
            "        # First convolutional layer with normalization\n",
            "        self.conv1 = nn.LazyConv2d(\n",
            "            num_channels // factor, kernel_size=1, padding=0, bias=use_bias\n",
            "        )\n",
            "        self.bn1 = nn.LazyBatchNorm2d()\n",
            "\n",
            "        # Second convolutional layer with normalization\n",
            "        self.conv2 = nn.LazyConv2d(\n",
            "            num_channels // factor,\n",
            "            kernel_size=3,\n",
            "            padding=1,\n",
            "            stride=strides,\n",
            "            bias=use_bias,\n",
            "        )\n",
            "        self.bn2 = nn.LazyBatchNorm2d()\n",
            "\n",
            "        # Third convolutional layer with normalization\n",
            "        self.conv3 = nn.LazyConv2d(\n",
            "            num_channels, kernel_size=1, padding=0, bias=use_bias\n",
            "        )\n",
            "        self.bn3 = nn.LazyBatchNorm2d()\n",
            "\n",
            "        self.relu = nn.ReLU(inplace=True)\n",
            "\n",
            "        self.conv_stem = None\n",
            "        if use_stem:\n",
            "            # Bottleneck residual block\n",
            "            self.conv_stem = nn.LazyConv2d(\n",
            "                num_channels, kernel_size=1, stride=strides, bias=use_bias\n",
            "            )\n",
            "\n",
            "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
            "        shortcut = inputs\n",
            "        x = self.relu(self.bn1(self.conv1(inputs)))\n",
            "        if self.dropout1 is not None:\n",
            "            x = self.dropout1(x)\n",
            "        x = self.relu(self.bn2(self.conv2(x)))\n",
            "        if self.dropout2 is not None:\n",
            "            x = self.dropout2(x)\n",
            "        x = self.bn3(self.conv3(x))\n",
            "        if self.use_stem:\n",
            "            # downsample skip connection\n",
            "            shortcut = self.conv_stem(shortcut)\n",
            "\n",
            "        # add in skip connection\n",
            "        x += shortcut\n",
            "        return self.relu(x)\n",
            "\n",
            "\n",
            "class StemConfig:\n",
            "    \"\"\"\n",
            "    convenience class to encapsulate configuration options\n",
            "    for the ResNet stem\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, num_channels, kernel_size, stride, padding):\n",
            "        self.num_channels = num_channels\n",
            "        self.kernel_size = kernel_size\n",
            "        self.stride = stride\n",
            "        self.padding = padding\n",
            "\n",
            "\n",
            "def generate_block(\n",
            "    block_type: ResidualBlockType,\n",
            "    num_channels: int,\n",
            "    use_stem: bool = False,\n",
            "    strides: int = 1,\n",
            "    factor: int = 4,\n",
            "    dropout: Optional[float] = None,\n",
            "    use_bias: bool = False,\n",
            "    main_block_kernel_size: int = 3\n",
            "):\n",
            "    \"\"\"\n",
            "    Returns either a Residual Block or a ResidualBottleneck\n",
            "    \"\"\"\n",
            "    if block_type == ResidualBlockType.BASIC:\n",
            "        return ResidualBlock(\n",
            "            num_channels,\n",
            "            use_stem=use_stem,\n",
            "            strides=strides,\n",
            "            dropout=dropout,\n",
            "            use_bias=use_bias,\n",
            "            main_block_kernel_size=main_block_kernel_size\n",
            "        )\n",
            "    else:\n",
            "        return BottleneckResidualBlock(\n",
            "            num_channels,\n",
            "            use_stem=use_stem,\n",
            "            strides=strides,\n",
            "            factor=factor,\n",
            "            dropout=dropout,\n",
            "            use_bias=use_bias,\n",
            "            main_block_kernel_size=main_block_kernel_size\n",
            "        )\n",
            "\n",
            "\n",
            "class ResNet(nn.Module):\n",
            "    \"\"\"\n",
            "    Class representing a full ResNet model\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(\n",
            "        self,\n",
            "        architecture: List[Tuple[ResidualBlockType, int, int, float, int]],\n",
            "        stem_config: Optional[StemConfig],\n",
            "        output_size: int = 10,\n",
            "        use_bias: bool = False,\n",
            "        *args,\n",
            "        **kwargs,\n",
            "    ):\n",
            "        \"\"\"\n",
            "        returns an instance of a ResNet\n",
            "        \"\"\"\n",
            "        super().__init__()\n",
            "        self.use_bias = use_bias\n",
            "        if stem_config is not None:\n",
            "            self.stem = self.create_stem(\n",
            "                stem_config.num_channels,\n",
            "                stem_config.kernel_size,\n",
            "                stem_config.stride,\n",
            "                stem_config.padding,\n",
            "                use_bias=use_bias,\n",
            "            )\n",
            "        else:\n",
            "            self.stem = self.create_stem(use_bias=use_bias)\n",
            "        self.classifier = self.create_classifier(output_size, use_bias=use_bias)\n",
            "\n",
            "        self.body = nn.Sequential()\n",
            "        for idx, block_def in enumerate(architecture):\n",
            "            self.body.add_module(\n",
            "                f\"block_{idx+2}\",\n",
            "                self.create_block(\n",
            "                    *block_def, first_block=(idx == 0), use_bias=use_bias\n",
            "                ),\n",
            "            )\n",
            "\n",
            "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
            "        \"\"\"\n",
            "        Performs forward pass of the inputs through the network\n",
            "        \"\"\"\n",
            "        x = self.stem(inputs)\n",
            "        x = self.body(x)\n",
            "        return self.classifier(x)\n",
            "\n",
            "    def create_stem(\n",
            "        self,\n",
            "        num_channels: int = 64,\n",
            "        kernel_size: int = 7,\n",
            "        stride: int = 2,\n",
            "        padding: int = 3,\n",
            "        use_bias: bool = False,\n",
            "    ) -> nn.Sequential:\n",
            "        \"\"\"\n",
            "        Creates a sequential stem as the first component of the model\n",
            "        \"\"\"\n",
            "        return nn.Sequential(\n",
            "            nn.LazyConv2d(\n",
            "                num_channels,\n",
            "                kernel_size=kernel_size,\n",
            "                padding=padding,\n",
            "                stride=stride,\n",
            "                bias=use_bias,\n",
            "            ),\n",
            "            nn.LazyBatchNorm2d(),\n",
            "            nn.ReLU(inplace=True),\n",
            "        )\n",
            "\n",
            "    def create_classifier(\n",
            "        self, num_classes: int, use_bias: bool = False\n",
            "    ) -> nn.Sequential:\n",
            "        \"\"\"\n",
            "        Creates a sequential classifier head at the very\n",
            "        \"\"\"\n",
            "        return nn.Sequential(\n",
            "            nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.LazyLinear(num_classes)\n",
            "        )\n",
            "\n",
            "    def create_block(\n",
            "        self,\n",
            "        block_type: ResidualBlockType,\n",
            "        num_residuals: int,\n",
            "        num_channels: int,\n",
            "        dropout: Optional[float] = None,\n",
            "        main_block_kernel_size: int = 3,\n",
            "        first_block: bool = False,\n",
            "        use_bias: bool = False,\n",
            "    ) -> nn.Sequential:\n",
            "        \"\"\"\n",
            "        Given our inputs, generates either a ResidualBlock or ResidualBottleNeck and addes it to our\n",
            "        sequence of layers\n",
            "        \"\"\"\n",
            "        layer = []\n",
            "        for i in range(num_residuals):\n",
            "            if i == 0 and not first_block:\n",
            "                layer.append(\n",
            "                    generate_block(\n",
            "                        block_type,\n",
            "                        num_channels,\n",
            "                        use_stem=True,\n",
            "                        strides=2,\n",
            "                        dropout=dropout,\n",
            "                        use_bias=use_bias,\n",
            "                        main_block_kernel_size=main_block_kernel_size\n",
            "                    )\n",
            "                )\n",
            "            else:\n",
            "                layer.append(\n",
            "                    generate_block(\n",
            "                        block_type, num_channels, dropout=dropout, use_bias=use_bias, \n",
            "                        main_block_kernel_size=main_block_kernel_size\n",
            "                    )\n",
            "                )\n",
            "        return nn.Sequential(*layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geVocFZngwER"
      },
      "source": [
        "# Import, Seed, Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yk6T4FzhgvGv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-QebqUCUgyc-"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lsMOOo-gzTu",
        "outputId": "686e69ea-7d96-412a-cdc2-53b6099e469e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br5Rha2PhBoT"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "ce7737566c49423e86bf5b2254159e59",
            "34fe54ac597b4dc5b7e036de6c82fffe",
            "9d52cd182cdb43bcbff77aa8937701bc",
            "3ef6484937da4ea78d02142ca90ce61b",
            "0960aa56123041d2ab181ccf6f862710",
            "5399d023c0d948cab8bd106c70963b09",
            "3999e007edd44fd48dfc759617eadc73",
            "42c0dfbc520e4046b5dfffe60ed98a59",
            "963017926752479f9c4a567a1ed71ae3",
            "b159c2a9762246489399aa427183f69b",
            "416ce670a7584df1bc5416656583b12a"
          ]
        },
        "id": "XD28XJ_qg1Ee",
        "outputId": "50347830-6950-4066-9eb3-3c202495277e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce7737566c49423e86bf5b2254159e59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/cifar-10-python.tar.gz to .data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from src.data import get_transformed_data, make_data_loaders\n",
        "from src.transforms import make_auto_transforms # used to use: make_transforms\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "VALID_RATIO = 0.1\n",
        "\n",
        "train_data, valid_data, test_data = \\\n",
        "get_transformed_data(make_transforms=make_auto_transforms, valid_ratio=VALID_RATIO)\n",
        "\n",
        "train_iter, valid_iter, test_iter = \\\n",
        "make_data_loaders(train_data, valid_data, test_data, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P0KpocliyKi"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model: import"
      ],
      "metadata": {
        "id": "09YbNCaCYxMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model import StemConfig, ResidualBlockType, ResNet"
      ],
      "metadata": {
        "id": "jCSim-9qY1V4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model: try code here\n",
        "`config_kernel_size_on_updated_main` branch > src > model.py"
      ],
      "metadata": {
        "id": "MrDIWjVaY2PV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F10Lm95gY5sG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftpl9IQRYpEX"
      },
      "source": [
        "## Architecture <<<"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ORrGNYQGix9m"
      },
      "outputs": [],
      "source": [
        "DROPOUT = 0.1\n",
        "MAIN_BLOCK_KERNEL_SIZE = 2\n",
        "\n",
        "# 1 tuple == 1 layer\n",
        "# block with or without bottleneck, how many blocks in each layer, out_channels, dropout prob, kernel_size\n",
        "architecture = [\n",
        "    (ResidualBlockType.BASIC, 2,  64, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
        "    (ResidualBlockType.BASIC, 2, 128, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
        "    (ResidualBlockType.BASIC, 2, 256, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
        "    (ResidualBlockType.BASIC, 2, 512, DROPOUT, MAIN_BLOCK_KERNEL_SIZE),\n",
        "]\n",
        "\n",
        "# 2022.11/18(5)_p03.59 (Oscar)\n",
        "# slightly reduce the last layer's out_channels to keep overall params under 5M:\n",
        "# 512 -> 5,069,130\n",
        "# 508 -> 5,014,978\n",
        "# 507 -> 5,001,500\n",
        "# 506 -> 4,988,046 <<<"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bz6S1KmzOjda"
      },
      "outputs": [],
      "source": [
        "config = StemConfig(num_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "model  = ResNet(architecture, stem_config=config, output_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LwVNRxIUnAJ"
      },
      "source": [
        "## Initialize model shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5Dw4mJFmkKu",
        "outputId": "a38b3f0f-c718-4ef8-fcb3-4ea458befc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------\n",
            "-------------------\n",
            "ResNet(\n",
            "  (stem): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            "  (body): Sequential(\n",
            "    (block_2): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (identity): Identity()\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (identity): Identity()\n",
            "      )\n",
            "    )\n",
            "    (block_3): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv_stem): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (identity): Identity()\n",
            "      )\n",
            "    )\n",
            "    (block_4): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv_stem): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (identity): Identity()\n",
            "      )\n",
            "    )\n",
            "    (block_5): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv_stem): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (out): ReLU(inplace=True)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (identity): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(5069130, 5069130)\n",
            "torch.Size([128, 10])\n"
          ]
        }
      ],
      "source": [
        "# intialize a new model\n",
        "\n",
        "inputs = torch.empty((BATCH_SIZE, 3, 32, 32)) #  passed\n",
        "inputs.normal_()\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "outputs = model(inputs.to(device)) # internally converts all nn.LazyConv2d layers to nn.Conv2d\n",
        "\n",
        "print('-------------------')\n",
        "print('-------------------')\n",
        "\n",
        "print(model)\n",
        "\n",
        "from src.utils import count_parameters\n",
        "\n",
        "print(count_parameters(model))\n",
        "print(outputs.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWvfEz42UfD0"
      },
      "source": [
        "## Count parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJeHP8QWT_mQ",
        "outputId": "a474eac0-fbb1-453c-85fe-0d4d04768386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5069130\n"
          ]
        }
      ],
      "source": [
        "num_parameters, num_parameters_requiring_grad = count_parameters(model)\n",
        "print(num_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuhd85NQdSVI",
        "outputId": "f9378372-6c30-445b-edf8-c6aa2fb939fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
              "|    Conv2d: 2-1                       [-1, 64, 32, 32]          1,728\n",
              "|    BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
              "|    ReLU: 2-3                         [-1, 64, 32, 32]          --\n",
              "Sequential: 1-2                        [-1, 512, 4, 4]           --\n",
              "|    Sequential: 2-4                   [-1, 64, 32, 32]          --\n",
              "|    |    ResidualBlock: 3-1           [-1, 64, 32, 32]          33,024\n",
              "|    |    ResidualBlock: 3-2           [-1, 64, 32, 32]          33,024\n",
              "|    Sequential: 2-5                   [-1, 128, 16, 16]         --\n",
              "|    |    ResidualBlock: 3-3           [-1, 128, 16, 16]         107,008\n",
              "|    |    ResidualBlock: 3-4           [-1, 128, 16, 16]         131,584\n",
              "|    Sequential: 2-6                   [-1, 256, 8, 8]           --\n",
              "|    |    ResidualBlock: 3-5           [-1, 256, 8, 8]           427,008\n",
              "|    |    ResidualBlock: 3-6           [-1, 256, 8, 8]           525,312\n",
              "|    Sequential: 2-7                   [-1, 512, 4, 4]           --\n",
              "|    |    ResidualBlock: 3-7           [-1, 512, 4, 4]           1,705,984\n",
              "|    |    ResidualBlock: 3-8           [-1, 512, 4, 4]           2,099,200\n",
              "Sequential: 1-3                        [-1, 10]                  --\n",
              "|    AdaptiveAvgPool2d: 2-8            [-1, 512, 1, 1]           --\n",
              "|    Flatten: 2-9                      [-1, 512]                 --\n",
              "|    Linear: 2-10                      [-1, 10]                  5,130\n",
              "==========================================================================================\n",
              "Total params: 5,069,130\n",
              "Trainable params: 5,069,130\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 28.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 5.19\n",
              "Params size (MB): 19.34\n",
              "Estimated Total Size (MB): 24.54\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "QUIET_VERBOSE = 0\n",
        "\n",
        "one_sample_input_shape = (3, 32, 32)\n",
        "\n",
        "summary(model, one_sample_input_shape, verbose = QUIET_VERBOSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQKBIE8_UgoP"
      },
      "source": [
        "## Initialize parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXBP9Cm0Up-h"
      },
      "outputs": [],
      "source": [
        "from src.utils import initialize_parameters\n",
        "\n",
        "# initialize model weights\n",
        "model.apply(initialize_parameters);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xAeC3JkTZPn"
      },
      "source": [
        "# Train, validate, log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbTgjcLMYpEa"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNYcxMz6YpEa"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RticcmCFYpEa"
      },
      "source": [
        "## Optimizer, scheduler (learning rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOacAoIeYpEb"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "learning_rate = 0.01\n",
        "max_lr        = 0.5\n",
        "base_lr       = 0.0001\n",
        "\n",
        "lr_schedule   = 'CyclicLR_base_0.0001_max_0.5'\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=learning_rate, cycle_momentum=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSDlhXutYpEb"
      },
      "source": [
        "## Iterate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8RjsKs0ZjgD"
      },
      "outputs": [],
      "source": [
        "from src.engine import train_one_epoch, evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvkyK2UgYpEb"
      },
      "outputs": [],
      "source": [
        "EPOCHS  = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "VwTSlzxwTwLf",
        "outputId": "1ea3c3e8-51ae-4a73-b6dc-2c1e22f4cb78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'architecture': [(<ResidualBlockType.BASIC: 0>, 2, 64, 0.1, 2),\n",
              "  (<ResidualBlockType.BASIC: 0>, 2, 128, 0.1, 2),\n",
              "  (<ResidualBlockType.BASIC: 0>, 2, 256, 0.1, 2),\n",
              "  (<ResidualBlockType.BASIC: 0>, 2, 512, 0.1, 2)],\n",
              " 'num_params': 5069130,\n",
              " 'main_block_kernel_size': 2,\n",
              " 'dropout': 0.1,\n",
              " 'learning_rate': 0.01,\n",
              " 'batch_size': 128,\n",
              " 'epochs': 3}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## setup wandb logging\n",
        "\n",
        "assert 'wandb' in locals() # 'wandb' has been imported already\n",
        "\n",
        "ENTITY_NAME  = 'dlf22_mini_project' # this is our team name\n",
        "\n",
        "# PROJECT_NAME = 'Junk_Test_Project'\n",
        "PROJECT_NAME = 'ResNet_5M'\n",
        "\n",
        "# RUN_NAME     = 'resnet_osca_kernel_size_2_2022.11.18.p04.13'\n",
        "RUN_NAME = 'osca_kernel_size_2_replicate_resnet18_adamw'\n",
        "\n",
        "WANDB_CONFIG = \\\n",
        "{\"architecture\"          : architecture,                 # the model\n",
        " \"num_params\"            : num_parameters,                # the model\n",
        " \"grad_params\"           : num_parameters_requiring_grad, # the model\n",
        " \"main_block_kernel_size\": MAIN_BLOCK_KERNEL_SIZE,        # the model\n",
        " \"dropout\"       : DROPOUT,         # the model\n",
        " \"learning_rate\" : learning_rate,   # how to gradient descent\n",
        " \"lr_schedule\"   : lr_schedule,     # how to gradient descent\n",
        " \"batch_size\"    : BATCH_SIZE,      # how to gradient descent\n",
        " \"epochs\"        : EPOCHS,}         # train for how long\n",
        "\n",
        "WANDB_CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAHgrLh_YpEc",
        "outputId": "b677f79f-6357-4a5e-ad27-686a6c8b47d3",
        "colab": {
          "referenced_widgets": [
            "69397ab6bdff44ada4023f7d9f303a68",
            "47395a619df1433e873a3f0b3e5b07ef"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:36sd927z) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69397ab6bdff44ada4023f7d9f303a68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">osca_kernel_size_2_replicate_resnet18_adamw</strong>: <a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/36sd927z\" target=\"_blank\">https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/36sd927z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221119_143635-36sd927z/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:36sd927z). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47395a619df1433e873a3f0b3e5b07ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668257250012176, max=1.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/studio-lab-user/sagemaker-studiolab-notebooks/wandb/run-20221119_143756-1nxktffy</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/1nxktffy\" target=\"_blank\">osca_kernel_size_2_replicate_resnet18_adamw</a></strong> to <a href=\"https://wandb.ai/dlf22_mini_project/ResNet_5M\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dlf22_mini_project/ResNet_5M/runs/1nxktffy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f240810ee20>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb\\\n",
        ".init(name=RUN_NAME, project=PROJECT_NAME, entity=ENTITY_NAME,config=WANDB_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMyGRL1GUGXH",
        "outputId": "8d125113-5e46-4c5d-963c-7142380b96f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "osca_kernel_size_2_replicate_resnet18_adamw.pt\n"
          ]
        }
      ],
      "source": [
        "# save to disk the \"best\" model === the model with the lowest validation loss\n",
        "best_model_path = RUN_NAME + '.pt'\n",
        "print(best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbWjFOiMULJ3",
        "outputId": "7a24b9cb-06a6-468c-fe23-fac31086cd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\tTrain elapsed: 1:5, loss: 2.0357, acc: 27.80%\n",
            "\tValidation elapsed: 0:1, loss: 1.6630, acc: 39.04%\n",
            "0.00010495000000000166\n",
            "Epoch 2\n",
            "\tTrain elapsed: 1:2, loss: 1.6995, acc: 38.63%\n",
            "\tValidation elapsed: 0:1, loss: 1.4054, acc: 49.10%\n",
            "0.00010989999999999892\n",
            "Epoch 3\n",
            "\tTrain elapsed: 1:4, loss: 1.5574, acc: 43.62%\n",
            "\tValidation elapsed: 0:1, loss: 1.2502, acc: 54.84%\n",
            "0.00011485000000000057\n"
          ]
        }
      ],
      "source": [
        "from src.utils import epoch_time\n",
        "\n",
        "FIRST_EPOCH = 1\n",
        "\n",
        "best_loss = float('inf')\n",
        "for epoch in range(FIRST_EPOCH, FIRST_EPOCH + EPOCHS):\n",
        "\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    \n",
        "    ## TRAIN\n",
        "    start = time.time()\n",
        "    # train\n",
        "    train_loss, train_acc  = train_one_epoch(model, train_iter, criterion, optimizer, device)\n",
        "    # log & echo\n",
        "    train_mins, train_secs = epoch_time(start, time.time())\n",
        "    wandb.log({\"train_loss\": train_loss,\n",
        "               \"train_acc\" : train_acc,\n",
        "               \"epoch\"     : epoch})\n",
        "    print(f\"\\tTrain elapsed: {train_mins}:{train_secs}, loss: {train_loss:.4f}, acc: {train_acc * 100:.2f}%\")\n",
        "\n",
        "    ## VALIDATE\n",
        "    start = time.time()\n",
        "    # validate\n",
        "    val_loss, val_acc  = evaluate(model, valid_iter, criterion, device)\n",
        "    # log & echo   \n",
        "    val_mins, val_secs = epoch_time(start, time.time())\n",
        "    wandb.log({\"val_loss\": val_loss,\n",
        "               \"val_acc\" : val_acc,\n",
        "               \"epoch\"   : epoch,})\n",
        "    print(f\"\\tValidation elapsed: {val_mins}:{val_secs}, loss: {val_loss:.4f}, acc: {val_acc * 100:.2f}%\")\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(current_lr)\n",
        "    wandb.log({\"current_lr\": current_lr,\n",
        "               \"epoch\"     : epoch})\n",
        "    \n",
        "    ## Memorize \"best\" model === the model with the lowest validation loss\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGr403ktYpEc"
      },
      "source": [
        "# Test, log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0myntf_YpEd",
        "outputId": "90b68992-f0a8-4b81-9ea8-5c50db781cb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "osca_kernel_size_2_replicate_resnet18_adamw.pt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(best_model_path),\n",
        "model.load_state_dict(torch.load(best_model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuDFGLo_YpEd",
        "outputId": "6af098b6-603e-48d4-f19d-a95955a7da72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 1.2691\n",
            "Test Accuracy: 53.74%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = evaluate(model.to(device), test_iter, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_acc\" : test_acc,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXJRW1GLYpEd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce7737566c49423e86bf5b2254159e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34fe54ac597b4dc5b7e036de6c82fffe",
              "IPY_MODEL_9d52cd182cdb43bcbff77aa8937701bc",
              "IPY_MODEL_3ef6484937da4ea78d02142ca90ce61b"
            ],
            "layout": "IPY_MODEL_0960aa56123041d2ab181ccf6f862710"
          }
        },
        "34fe54ac597b4dc5b7e036de6c82fffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5399d023c0d948cab8bd106c70963b09",
            "placeholder": "",
            "style": "IPY_MODEL_3999e007edd44fd48dfc759617eadc73",
            "value": "100%"
          }
        },
        "9d52cd182cdb43bcbff77aa8937701bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c0dfbc520e4046b5dfffe60ed98a59",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_963017926752479f9c4a567a1ed71ae3",
            "value": 170498071
          }
        },
        "3ef6484937da4ea78d02142ca90ce61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b159c2a9762246489399aa427183f69b",
            "placeholder": "",
            "style": "IPY_MODEL_416ce670a7584df1bc5416656583b12a",
            "value": " 170498071/170498071 [00:10&lt;00:00, 17699699.31it/s]"
          }
        },
        "0960aa56123041d2ab181ccf6f862710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5399d023c0d948cab8bd106c70963b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3999e007edd44fd48dfc759617eadc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42c0dfbc520e4046b5dfffe60ed98a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963017926752479f9c4a567a1ed71ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b159c2a9762246489399aa427183f69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416ce670a7584df1bc5416656583b12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}